{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "import pyautogui\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Refresh Yes\n"
     ]
    }
   ],
   "source": [
    "which = pyautogui.confirm(text='Select Model:', buttons=['SVR - Poly', 'NN', 'SVR - Lin', 'Linear'])\n",
    "load = pyautogui.confirm(text='Refresh or Existing Data:', buttons=['Refresh', 'Existing'])\n",
    "tolog = pyautogui.confirm(text='Log Target Data?', buttons=['Yes', 'No'])\n",
    "print(which, load, tolog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 3)\n",
      "(2917, 345)\n",
      "(2917, 110)\n"
     ]
    }
   ],
   "source": [
    "dropcolumns = 235\n",
    "\n",
    "inputs = pd.read_csv('traincleaned.csv')\n",
    "testinputs = pd.read_csv('testcleaned.csv')\n",
    "featureimportance = pd.read_csv('feature importance.csv')\n",
    "print(featureimportance.shape)\n",
    "featureimportance = featureimportance.rename(columns={'0': 'importance', '1':'feature'})\n",
    "featureimportance = featureimportance.drop(columns=['Unnamed: 0'])\n",
    "featureimportance = featureimportance.sort_values(by='importance')\n",
    "featureimportance = featureimportance[0:dropcolumns]\n",
    "featureimportance = featureimportance['feature'].tolist()\n",
    "\n",
    "inputs = inputs.drop(columns=['SalePrice'])\n",
    "alldata = pd.concat([inputs, testinputs])\n",
    "alldata.set_index('Id', inplace=True)\n",
    "alldata = alldata.fillna(0)\n",
    "alldata = pd.get_dummies(alldata)\n",
    "alldata = alldata.drop(columns=['Unnamed: 0'])\n",
    "print(alldata.shape)\n",
    "for column in featureimportance:\n",
    "    try:\n",
    "        alldata = alldata.drop(columns=column)\n",
    "    except:\n",
    "        print(f'Couldnt drop column {column}')\n",
    "\n",
    "print(alldata.shape)\n",
    "\n",
    "inputs = alldata.loc[0:1460,]\n",
    "testinputs = alldata.loc[1461:]\n",
    "\n",
    "numericalcolumns = []\n",
    "for column in inputs.columns:\n",
    "    if set(inputs[column].tolist()) != {0, 1}:\n",
    "        numericalcolumns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.31910606, 5.25887663, 5.34927753, ..., 5.42569721, 5.15267048,\n",
       "       5.16879202])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "prices = pd.read_csv('traincleaned.csv')\n",
    "prices = prices['SalePrice']\n",
    "prices = np.array(prices)\n",
    "if tolog == 'Yes':\n",
    "    prices = np.log10(prices)\n",
    "# Y_scaler = StandardScaler().fit(prices.reshape(-1,1))\n",
    "# prices = Y_scaler.fit_transform(prices.reshape(-1,1))\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 110) (1458,)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape, prices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle\n",
    "\n",
    "if load == 'Refresh' and which == 'Linear':\n",
    "    \n",
    "#     bins = np.linspace(prices.min(), prices.max(), 4)\n",
    "#     print(bins)\n",
    "#     y_binned = np.digitize(prices, bins)\n",
    "\n",
    "#     print(np.count_nonzero(y_binned == 1), np.count_nonzero(y_binned == 2), np.count_nonzero(y_binned == 3))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, prices, random_state=10, shuffle=True, test_size=.15)\n",
    "    \n",
    "\n",
    "    for column in numericalcolumns:\n",
    "        try:\n",
    "            if which == 'NN':\n",
    "                X_scaler = MinMaxScaler().fit(X_train[column].values.reshape(-1,1))\n",
    "            else:\n",
    "                X_scaler = StandardScaler().fit(X_train[column].values.reshape(-1,1))\n",
    "                \n",
    "            \n",
    "            X_train[column] = X_scaler.fit_transform(X_train[column].values.reshape(-1,1))\n",
    "            X_test[column] = X_scaler.fit_transform(X_test[column].values.reshape(-1,1))\n",
    "            testinputs[column] = X_scaler.fit_transform(testinputs[column].values.reshape(-1,1))\n",
    "            inputs[column] = X_scaler.fit_transform(inputs[column].values.reshape(-1,1))\n",
    "            \n",
    "#             X_train[column] = np.log10(X_train[column])\n",
    "#             X_test[column] = np.log10(X_test[column])\n",
    "#             testinputs[column] = np.log10(testinputs[column])\n",
    "#             inputs[column] = np.log10(inputs[column])\n",
    "        except Exception as e:\n",
    "            print(column, e)\n",
    "\n",
    "#     y_scaler = MinMaxScaler().fit(y_train.reshape(-1,1))\n",
    "#     y_train = y_scaler.fit_transform(y_train.reshape(-1,1))\n",
    "#     y_test = y_scaler.fit_transform(y_test.reshape(-1,1)) \n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    testinputs = testinputs.values\n",
    "    inputs = inputs.values\n",
    "    \n",
    "    objects = [X_train, X_test, testinputs, inputs, y_train, y_test]\n",
    "\n",
    "    with open(\"objects.txt\", \"wb\") as fp:\n",
    "        pickle.dump(objects, fp)\n",
    "        \n",
    "else:\n",
    "    if which != 'Linear':\n",
    "        with open(\"objects.txt\", \"rb\") as fp:\n",
    "            objects = pickle.load(fp)\n",
    "\n",
    "        X_train, X_test, testinputs, inputs, y_train, y_test = objects   \n",
    "    \n",
    "if which == 'Linear':\n",
    "    pass\n",
    "#     testinputs = testinputs.values\n",
    "#     inputs = inputs.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 110)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\brand\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 444       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 457\n",
      "Trainable params: 457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if which == 'NN':\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation\n",
    "    import keras.backend as K\n",
    "    import tensorflow as tf\n",
    "    from keras import optimizers\n",
    "    from keras import regularizers\n",
    "\n",
    "    def compilemodel():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=4,\n",
    "                        activation='relu',\n",
    "                       input_dim=inputs.shape[1]))#,\n",
    "                        #kernel_regularizer=regularizers.l2(0.0001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(units=2,\n",
    "                        activation='relu',\n",
    "                       input_dim=inputs.shape[1],\n",
    "                         kernel_regularizer=regularizers.l2(0.0001)))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1,\n",
    "                       activation='linear'))#,\n",
    "                       #kernel_regularizer=regularizers.l2(0.0001)))\n",
    "\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "        return model\n",
    "\n",
    "    model = compilemodel()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.31910606, 5.25887663, 5.34927753, ..., 5.42569721, 5.15267048,\n",
       "       5.16879202])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = compilemodel()\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=500,\n",
    "#     shuffle=True,\n",
    "#     verbose=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "# metrics = list(history.history.keys())\n",
    "# style = ['r-','ro','b-','bo']\n",
    "\n",
    "# plt.figure() \n",
    "# for metric,style in  zip(metrics,style): \n",
    "    \n",
    "#     plt.plot(history.history[metric],style,label=metric)\n",
    "    \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which = 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "totalepochs = 0\n",
    "timethrough = 0\n",
    "\n",
    "\n",
    "\n",
    "testRMSLElist = []\n",
    "trainRMSLElist = []\n",
    "difflist = []\n",
    "\n",
    "while which == 'NN':\n",
    "    \n",
    "    model = compilemodel()\n",
    "\n",
    "    \n",
    "    for x in range(epochs):\n",
    "\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=1,\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "        )\n",
    "        if x % 5 == 0 and x != 0:\n",
    "            testpredictions = model.predict(X_test)\n",
    "            trainpredictions = model.predict(X_train)\n",
    "\n",
    "            testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "            trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "            \n",
    "            if tolog == 'Yes':\n",
    "                testpredictions = np.power(10, testpredictions)\n",
    "                trainpredictions = np.power(10, trainpredictions)\n",
    "                y_test = np.power(10, y_test)\n",
    "                y_train = np.power(10, y_train)\n",
    "\n",
    "\n",
    "            testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "            trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "            diff = round(abs(testRMSLE - trainRMSLE), 4)\n",
    "            \n",
    "            testRMSLElist.append(testRMSLE)\n",
    "            trainRMSLElist.append(trainRMSLE)\n",
    "            difflist.append(diff)\n",
    "            \n",
    "            if tolog == 'Yes':\n",
    "                testpredictions = np.log10(testpredictions)\n",
    "                trainpredictions = np.log10(trainpredictions)\n",
    "                y_test = np.log10(y_test)\n",
    "                y_train = np.log10(y_train)\n",
    "\n",
    "            clear_output()\n",
    "            xaxis = np.arange(0, len(testRMSLElist) * 5, 5)\n",
    "            plt.plot(xaxis, trainRMSLElist, 'r--', label='train')\n",
    "            plt.plot(xaxis, testRMSLElist, label='test')\n",
    "            plt.legend()\n",
    "            \n",
    "            \n",
    "            plt.ylim(0, .25)\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "            print(f'{x + 1 + timethrough * epochs}, trainRMSLE = {round(trainRMSLE,4)}, testRMSLE={round(testRMSLE, 4)}, diff={diff}')        \n",
    "\n",
    "\n",
    "    totalepochs+=epochs\n",
    "    timethrough+=1\n",
    "    which = pyautogui.confirm(buttons=['NN', 'stop'])\n",
    "    if which == 'stop':\n",
    "        which = 'NN'\n",
    "        error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if which == 'NN':\n",
    "\n",
    "    folds = 1\n",
    "    epochs = 500\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    kf.get_n_splits(inputs, prices)\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(inputs, prices)):\n",
    "        X_train.append(inputs[train_index])\n",
    "        X_test.append(inputs[test_index])\n",
    "        y_train.append(prices[train_index])\n",
    "        y_test.append(prices[test_index])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    historylist = []\n",
    "\n",
    "    for fold in range(folds):\n",
    "        clear_output()\n",
    "        print(fold + 1)\n",
    "        \n",
    "        model = compilemodel()\n",
    "        \n",
    "        historylist.append(model.fit(\n",
    "            X_train[fold],\n",
    "            y_train[fold],\n",
    "            validation_data=(X_test[fold], y_test[fold]),\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "        ))\n",
    "    \n",
    "    clear_output()\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if which == 'NN':\n",
    "    addlist = {}\n",
    "    for key in historylist[0].history.keys():\n",
    "        addlist[key] = []\n",
    "        for fold in range(folds):\n",
    "            addlist[key].append(historylist[fold].history[key])\n",
    "\n",
    "    dftrainmse = pd.DataFrame()\n",
    "    dftestmse = pd.DataFrame()\n",
    "\n",
    "    for fold in range(folds):        \n",
    "        dftestmse[fold] = addlist['val_mean_squared_error'][fold]\n",
    "        dftrainmse[fold] = addlist['mean_squared_error'][fold]\n",
    "\n",
    "    dftestmse['avg'] = dftestmse.mean(axis=1)\n",
    "    dftrainmse['avg'] = dftrainmse.mean(axis=1)\n",
    "\n",
    "    avgtestmse = dftestmse['avg'].tolist()\n",
    "    avgtrainmse = dftrainmse['avg'].tolist()\n",
    "\n",
    "\n",
    "    plt.plot(avgtrainmse, 'r--', label = 'train')\n",
    "    plt.plot(avgtestmse, label = 'test')\n",
    "    plt.ylim(0, .3)\n",
    "    # plt.xlim(150, 300)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN' or which == 'stop':\n",
    "    which = 'NN'\n",
    "    totalepochs = int(pyautogui.prompt(text='Enter epochs', default=totalepochs))\n",
    "    print(f'Epochs = {totalepochs}')\n",
    "    model = compilemodel()\n",
    "    model.fit(\n",
    "        inputs,\n",
    "        prices,\n",
    "        epochs=totalepochs,\n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "    predictions = model.predict(testinputs)\n",
    "    predictions[predictions < prices.min()/2] = prices.min()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    print(predictions[0][0], len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    predicted = model.predict(X_test)\n",
    "    # y_train = np.power(10, y_train)\n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    if tolog == 'Yes':\n",
    "        predicted_graph = np.power(10, predicted)\n",
    "        y_test_graph = np.power(10, y_test)\n",
    "    else:\n",
    "        predicted_graph = predicted\n",
    "        y_test_graph = y_test\n",
    "        \n",
    "    print(predicted_graph.shape, y_test_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_test_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    predicted = model.predict(X_train)\n",
    "    if tolog == 'Yes':\n",
    "        predicted_graph = np.power(10, predicted)\n",
    "        y_train_graph = np.power(10, y_train)\n",
    "    else:\n",
    "        predicted_graph = predicted\n",
    "        y_train_graph = y_train\n",
    "        \n",
    "    print(predicted_graph.shape, y_train_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_train_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    lastRMSLE = 1\n",
    "    lastDiff = 1\n",
    "\n",
    "    for C in range(180, 220, 20):\n",
    "        print(f'C={C}')\n",
    "\n",
    "        for degree in range(5, 7):\n",
    "\n",
    "            for epsilon in [0.1, 1, 10, 20, 50, 75, 100]:\n",
    "\n",
    "                \n",
    "                for coef0 in range(2,3):\n",
    "                    clf = SVR(kernel='poly', C=C, gamma='auto', degree=degree, epsilon=epsilon, coef0=coef0)\n",
    "                    clf.fit(X_train, y_train) \n",
    "                    testpredictions = clf.predict(X_test)\n",
    "                    trainpredictions = clf.predict(X_train)\n",
    "\n",
    "\n",
    "                    testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "                    trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "                    \n",
    "                    if tolog == 'Yes':\n",
    "                        testpredictions = np.power(10, testpredictions)\n",
    "                        trainpredictions = np.power(10, trainpredictions)\n",
    "                        y_test = np.power(10, y_test)\n",
    "                        y_train = np.power(10, y_train)\n",
    "                    \n",
    "\n",
    "                    testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "                    trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "                    if tolog == 'Yes':\n",
    "                        testpredictions = np.log10(testpredictions)\n",
    "                        trainpredictions = np.log10(trainpredictions)\n",
    "                        y_test = np.log10(y_test)\n",
    "                        y_train = np.log10(y_train)\n",
    "                    \n",
    "                    \n",
    "                    diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "                    lastDiff = .01\n",
    "                    if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "                        lastDiff = diff\n",
    "                        lastRMSLE = testRMSLE                    \n",
    "                        print(f'C={C}, degree={degree}, epsilon={epsilon}, coef0={coef0}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}, dropcolumns={dropcolumns}')\n",
    "                        Cbest = C\n",
    "                        degreebest = degree\n",
    "                        epsilonbest = epsilon\n",
    "                        coef0best = coef0\n",
    "        \n",
    "    print('---Done---')\n",
    "    #C=130,degree=7,epsilon=0.1,coef0=3 0.1359030945302552 first submission\n",
    "    #C=190,degree=9,epsilon=0.9,coef0=2 0.1359030945302552 second?\n",
    "    #C=100,degree=7,epsilon=0.1,coef0=2 0.1359030945302552\n",
    "    #C=200, degree=7, epsilon=4, coef0=2, standard scaler, no normalizing output data, 0.1248 Kaggle Score\n",
    "    #C=210, degree=5, epsilon=13, coef0=3, trainRMSLE = 0.1, testRMSLE=0.13396, diff=0.034, no feat eng, no target scaling, dropcolumns = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        y_train = np.power(10, y_train)\n",
    "        \n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    predicted_graph = predicted\n",
    "    y_test_graph = predicted\n",
    "    print(predicted_graph.shape, y_test_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_test_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    predicted = clf.predict(X_train)\n",
    "    if tolog == 'Yes':\n",
    "        y_train = np.power(10, y_train)\n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    predicted_graph = predicted\n",
    "    y_train_graph = predicted\n",
    "    print(predicted_graph.shape, y_train_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_train_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    try:\n",
    "#         clf = SVR(kernel='poly', gamma='auto', C=240, degree=5, epsilon=0.1, coef0=2)#base\n",
    "#         clf = SVR(kernel='poly', gamma='auto', C=100, degree=6, epsilon=0.1, coef0=2)\n",
    "        #C=280, degree=6, epsilon=0.1, coef0=2, with newly cleaned data\n",
    "        sfa\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=80, degree=5, epsilon=20, coef0=2)      \n",
    "        print('Used entered hyperparameters')\n",
    "        print(clf)\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=Cbest, degree=degreebest, epsilon=epsilonbest, coef0=coef0best)\n",
    "        print(f'C={Cbest}, degree={degreebest}, epsilon={epsilonbest}, coef0={coef0best}')\n",
    "    \n",
    "    clf.fit(inputs, prices) \n",
    "    predictions = clf.predict(testinputs)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "    predictions[predictions < y_train.min()/2] = y_train.min()\n",
    "    # predictions = Y_scaler.inverse_transform(predictions)\n",
    "\n",
    "\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - RBF':\n",
    "    \n",
    "    lastRMSLE = 1\n",
    "    for C in [1e0, 1e1, 1e2, 1e3]:\n",
    "\n",
    "        for gamma in np.logspace(-2, 2, 5):\n",
    "\n",
    "            for epsilon in range(1,10):\n",
    "                epsilon = epsilon/10\n",
    "\n",
    "                clf = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=epsilon)\n",
    "                clf.fit(X_train, y_train) \n",
    "                testpredictions = clf.predict(X_test)\n",
    "                trainpredictions = clf.predict(X_train)\n",
    "                \n",
    "                testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "                trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "                \n",
    "                if tolog == 'Yes':\n",
    "                    testpredictions = np.power(10, testpredictions)\n",
    "                    trainpredictions = np.power(10, trainpredictions)\n",
    "                    y_test = np.power(10, y_test)\n",
    "                    y_train = np.power(10, y_train)\n",
    "\n",
    "                testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "                trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "                if tolog == 'Yes':\n",
    "                    testpredictions = np.log10(testpredictions)\n",
    "                    trainpredictions = np.log10(trainpredictions)\n",
    "                    y_test = np.log10(y_test)\n",
    "                    y_train = np.log10(y_train)\n",
    "\n",
    "                diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "                lastDiff = .05\n",
    "                if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "                    lastDiff = diff\n",
    "                    lastRMSLE = testRMSLE                    \n",
    "                    print(f'C={C}, gamma={gamma}, epsilon={epsilon}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}')\n",
    "                    Cbest = C\n",
    "                    gammabest = gamma\n",
    "                    epsilonbest = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - RBF':\n",
    "    clf = SVR(kernel='rbf', C=Cbest, gamma=gammabest, epsilon=epsilonbest)\n",
    "    clf.fit(X_train, y_train) \n",
    "    predictions = clf.predict(testinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Lin':\n",
    "    \n",
    "    lastRMSLE = 1\n",
    "    lastDiff = 1\n",
    "\n",
    "    for C in range(1, 40, 1):\n",
    "\n",
    "        clf = SVR(kernel='linear', C=C, gamma='auto')\n",
    "        clf.fit(X_train, y_train) \n",
    "        testpredictions = clf.predict(X_test)\n",
    "        trainpredictions = clf.predict(X_train)\n",
    "        \n",
    "        testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "        trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "\n",
    "        if tolog == 'Yes':\n",
    "            testpredictions = np.power(10, testpredictions)\n",
    "            trainpredictions = np.power(10, trainpredictions)\n",
    "            y_test = np.power(10, y_test)\n",
    "            y_train = np.power(10, y_train)\n",
    "\n",
    "\n",
    "        try:\n",
    "            testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "            trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "        except Exception as e:\n",
    "            print(f'Error with {C}, {e}')\n",
    "            continue\n",
    "\n",
    "        if tolog == 'Yes':\n",
    "            testpredictions = np.log10(testpredictions)\n",
    "            trainpredictions = np.log10(trainpredictions)\n",
    "            y_test = np.log10(y_test)\n",
    "            y_train = np.log10(y_train)\n",
    "\n",
    "        diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "        lastDiff = .05\n",
    "        if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "            lastDiff = diff\n",
    "            lastRMSLE = testRMSLE                    \n",
    "            print(f'C={C}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}')\n",
    "            Cbest = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Lin':\n",
    "    try:\n",
    "        sa\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=16)      \n",
    "        print('Used entered hyperparameters')\n",
    "        print(clf)\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=Cbest)\n",
    "        print(f'C={Cbest}')\n",
    "    \n",
    "    clf.fit(inputs, prices) \n",
    "    predictions = clf.predict(testinputs)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "    predictions[predictions < y_train.min()/2] = y_train.min()\n",
    "    # predictions = Y_scaler.inverse_transform(predictions)\n",
    "\n",
    "\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9294304614982759, RMSLE: 0.10614678316383754, dropcolumns: 235\n"
     ]
    }
   ],
   "source": [
    "if which == 'Linear':\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fitting our model with all of our features in X\n",
    "    model.fit(inputs, prices)\n",
    "\n",
    "    score = model.score(inputs, prices)\n",
    "\n",
    "    predictions = model.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    predictions = model.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f'R2: {score}, RMSLE: {RMSLE}, dropcolumns: {dropcolumns}')\n",
    "    #0.12363, R2 Score = .94, RMSLE = .0977, no scaling, drop columns = 150\n",
    "    #.12054, R2: 0.9361934187245556, RMSLE: 0.10093248123296446, dropcolumns: 200\n",
    "    #.12057, R2: 0.9299809808208424, RMSLE: 0.10573194685650467, dropcolumns: 225, with all feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.10673656439286405, R2: 0.9286440820917012, dropcolumns: 235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for alpha in range(1):\n",
    "    alpha = alpha/10\n",
    "    lasso = Lasso(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = lasso.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = lasso.score(inputs, prices)\n",
    "\n",
    "    predictions = lasso.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")\n",
    "#.11974, alpha: 0.0, RMSLE: 0.1062362486329152, R2: 0.9293114626723123, dropcolumns: 225  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.10616069478710691, R2: 0.9294119659777746, dropcolumns: 235\n",
      "alpha: 0.1, RMSLE: 0.10707867981301657, R2: 0.9281859216974832, dropcolumns: 235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for alpha in range(2):\n",
    "    alpha = alpha/10\n",
    "    ridge = Ridge(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = ridge.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = ridge.score(inputs, prices)\n",
    "\n",
    "    predictions = ridge.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.1089319655373888, R2: 0.9256785274106578, dropcolumns: 243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "for alpha in range(1):\n",
    "    alpha = alpha/10\n",
    "    elasticnet = ElasticNet(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = elasticnet.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = elasticnet.score(inputs, prices)\n",
    "\n",
    "    predictions = elasticnet.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119969.32892965 161923.67163231 182702.38522791 ... 175420.26449944\n",
      " 119045.65382891 219756.45798814]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 2) 1459\n",
      "tolog = Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>122238.764481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>161656.950998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>181737.663181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>205457.308980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>180095.399097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  122238.764481\n",
       "1  1462  161656.950998\n",
       "2  1463  181737.663181\n",
       "3  1464  205457.308980\n",
       "4  1465  180095.399097"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submittest = pd.read_csv('testcleaned.csv')\n",
    "submittest = submittest[['Id']]\n",
    "submittest['SalePrice'] = predictions\n",
    "submittest.to_csv('BrandenSubmission.csv', index=False)\n",
    "print(submittest.shape, len(predictions))\n",
    "print(f'tolog = {tolog}')\n",
    "submittest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  0.,  1.,  2., 93.,  6.,  1.,  1.,  0.,  3.]),\n",
       " array([-8.39612319e+11, -6.68332862e+11, -4.97053406e+11, -3.25773950e+11,\n",
       "        -1.54494493e+11,  1.67849628e+10,  1.88064419e+11,  3.59343875e+11,\n",
       "         5.30623332e+11,  7.01902788e+11,  8.73182244e+11]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014828069802926043"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_groupings = {}\n",
    "\n",
    "for i, column in enumerate(alldata.columns):\n",
    "    column = column.split('_')\n",
    "    if len(column) < 2:\n",
    "        continue \n",
    "    elif column[0] in category_groupings: \n",
    "        category_groupings[column[0]].append((column[1],model.coef_[i]))\n",
    "    else: \n",
    "        category_groupings[column[0]] = [(column[1], model.coef_[i])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BsmtExposure': [('Gd', 0.018104255199432373), ('No', -0.003818988800048828)],\n",
      " 'BsmtFinType1': [('GLQ', 0.0063703060150146484)],\n",
      " 'BsmtQual': [('Ex', 0.013070344924926758), ('Gd', -0.0008902549743652344)],\n",
      " 'CentralAir': [('N', -64310136122.09516), ('Y', -64310136122.06989)],\n",
      " 'ExterQual': [('Ex', 0.017604589462280273),\n",
      "               ('Gd', 0.01984572410583496),\n",
      "               ('TA', 0.012427806854248047)],\n",
      " 'Exterior2nd': [('HdBoard', -0.0031337738037109375)],\n",
      " 'FireplaceQu': [('Ex', 0.006416440010070801),\n",
      "                 ('Gd', 0.008069276809692383),\n",
      "                 ('No Value', 9.393692016601562e-05),\n",
      "                 ('TA', 0.0016527175903320312)],\n",
      " 'Foundation': [('PConc', 0.012057185173034668)],\n",
      " 'GarageFinish': [('Fin', 0.043984055519104004),\n",
      "                  ('RFn', 0.04439091682434082),\n",
      "                  ('Unf', 0.03989362716674805)],\n",
      " 'GarageType': [('Attchd', 0.007798671722412109),\n",
      "                ('Detchd', 0.012584686279296875)],\n",
      " 'HeatingQC': [('Ex', 0.006577968597412109)],\n",
      " 'HouseStyle': [('2Story', -0.006189465522766113)],\n",
      " 'KitchenQual': [('Ex', 0.023591041564941406),\n",
      "                 ('Gd', 0.0021333694458007812),\n",
      "                 ('TA', -0.0006442070007324219)],\n",
      " 'LotShape': [('IR1', -0.011621475219726562), ('Reg', -0.01151728630065918)],\n",
      " 'MSZoning': [('RL', 0.0025925636291503906), ('RM', -0.016529560089111328)],\n",
      " 'MasVnrType': [('Stone', 0.004875361919403076)],\n",
      " 'Neighborhood': [('Crawfor', 0.06238150596618652)],\n",
      " 'RoofStyle': [('Gable', 0.001745566725730896), ('Hip', 0.0021314024925231934)],\n",
      " 'SaleCondition': [('Normal', 0.029448632150888443),\n",
      "                   ('Partial', -0.010177850723266602)],\n",
      " 'SaleType': [('New', 0.05163228511810303), ('WD', -0.004759073257446289)]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(category_groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
