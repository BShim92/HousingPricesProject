{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "import pyautogui\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Refresh Yes\n"
     ]
    }
   ],
   "source": [
    "which = pyautogui.confirm(text='Select Model:', buttons=['SVR - Poly', 'NN', 'SVR - Lin', 'Linear'])\n",
    "load = pyautogui.confirm(text='Refresh or Existing Data:', buttons=['Refresh', 'Existing'])\n",
    "tolog = pyautogui.confirm(text='Log Target Data?', buttons=['Yes', 'No'])\n",
    "print(which, load, tolog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 3)\n",
      "(2917, 345)\n",
      "(2917, 110)\n"
     ]
    }
   ],
   "source": [
    "dropcolumns = 235\n",
    "\n",
    "inputs = pd.read_csv('traincleaned.csv')\n",
    "testinputs = pd.read_csv('testcleaned.csv')\n",
    "featureimportance = pd.read_csv('feature importance.csv')\n",
    "print(featureimportance.shape)\n",
    "featureimportance = featureimportance.rename(columns={'0': 'importance', '1':'feature'})\n",
    "featureimportance = featureimportance.drop(columns=['Unnamed: 0'])\n",
    "featureimportance = featureimportance.sort_values(by='importance')\n",
    "featureimportance = featureimportance[0:dropcolumns]\n",
    "featureimportance = featureimportance['feature'].tolist()\n",
    "\n",
    "inputs = inputs.drop(columns=['SalePrice'])\n",
    "alldata = pd.concat([inputs, testinputs])\n",
    "alldata.set_index('Id', inplace=True)\n",
    "alldata = alldata.fillna(0)\n",
    "alldata = pd.get_dummies(alldata)\n",
    "alldata = alldata.drop(columns=['Unnamed: 0'])\n",
    "print(alldata.shape)\n",
    "for column in featureimportance:\n",
    "    try:\n",
    "        alldata = alldata.drop(columns=column)\n",
    "    except:\n",
    "        print(f'Couldnt drop column {column}')\n",
    "\n",
    "print(alldata.shape)\n",
    "\n",
    "inputs = alldata.loc[0:1460,]\n",
    "testinputs = alldata.loc[1461:]\n",
    "\n",
    "numericalcolumns = []\n",
    "for column in inputs.columns:\n",
    "    if set(inputs[column].tolist()) != {0, 1}:\n",
    "        numericalcolumns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.31910606, 5.25887663, 5.34927753, ..., 5.42569721, 5.15267048,\n",
       "       5.16879202])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "prices = pd.read_csv('traincleaned.csv')\n",
    "prices = prices['SalePrice']\n",
    "prices = np.array(prices)\n",
    "if tolog == 'Yes':\n",
    "    prices = np.log10(prices)\n",
    "# Y_scaler = StandardScaler().fit(prices.reshape(-1,1))\n",
    "# prices = Y_scaler.fit_transform(prices.reshape(-1,1))\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 110) (1458,)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape, prices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle\n",
    "\n",
    "if load == 'Refresh' and which == 'Linear':\n",
    "    \n",
    "#     bins = np.linspace(prices.min(), prices.max(), 4)\n",
    "#     print(bins)\n",
    "#     y_binned = np.digitize(prices, bins)\n",
    "\n",
    "#     print(np.count_nonzero(y_binned == 1), np.count_nonzero(y_binned == 2), np.count_nonzero(y_binned == 3))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, prices, random_state=10, shuffle=True, test_size=.15)\n",
    "    \n",
    "\n",
    "    for column in numericalcolumns:\n",
    "        try:\n",
    "            if which == 'NN':\n",
    "                X_scaler = MinMaxScaler().fit(X_train[column].values.reshape(-1,1))\n",
    "            else:\n",
    "                X_scaler = StandardScaler().fit(X_train[column].values.reshape(-1,1))\n",
    "                \n",
    "            \n",
    "            X_train[column] = X_scaler.fit_transform(X_train[column].values.reshape(-1,1))\n",
    "            X_test[column] = X_scaler.fit_transform(X_test[column].values.reshape(-1,1))\n",
    "            testinputs[column] = X_scaler.fit_transform(testinputs[column].values.reshape(-1,1))\n",
    "            inputs[column] = X_scaler.fit_transform(inputs[column].values.reshape(-1,1))\n",
    "            \n",
    "#             X_train[column] = np.log10(X_train[column])\n",
    "#             X_test[column] = np.log10(X_test[column])\n",
    "#             testinputs[column] = np.log10(testinputs[column])\n",
    "#             inputs[column] = np.log10(inputs[column])\n",
    "        except Exception as e:\n",
    "            print(column, e)\n",
    "\n",
    "#     y_scaler = MinMaxScaler().fit(y_train.reshape(-1,1))\n",
    "#     y_train = y_scaler.fit_transform(y_train.reshape(-1,1))\n",
    "#     y_test = y_scaler.fit_transform(y_test.reshape(-1,1)) \n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    testinputs = testinputs.values\n",
    "    inputs = inputs.values\n",
    "    \n",
    "    objects = [X_train, X_test, testinputs, inputs, y_train, y_test]\n",
    "\n",
    "    with open(\"objects.txt\", \"wb\") as fp:\n",
    "        pickle.dump(objects, fp)\n",
    "        \n",
    "else:\n",
    "    if which != 'Linear':\n",
    "        with open(\"objects.txt\", \"rb\") as fp:\n",
    "            objects = pickle.load(fp)\n",
    "\n",
    "        X_train, X_test, testinputs, inputs, y_train, y_test = objects   \n",
    "    \n",
    "if which == 'Linear':\n",
    "    pass\n",
    "#     testinputs = testinputs.values\n",
    "#     inputs = inputs.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 110)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\brand\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 444       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 457\n",
      "Trainable params: 457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if which == 'NN':\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation\n",
    "    import keras.backend as K\n",
    "    import tensorflow as tf\n",
    "    from keras import optimizers\n",
    "    from keras import regularizers\n",
    "\n",
    "    def compilemodel():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=4,\n",
    "                        activation='relu',\n",
    "                       input_dim=inputs.shape[1]))#,\n",
    "                        #kernel_regularizer=regularizers.l2(0.0001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(units=2,\n",
    "                        activation='relu',\n",
    "                       input_dim=inputs.shape[1],\n",
    "                         kernel_regularizer=regularizers.l2(0.0001)))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1,\n",
    "                       activation='linear'))#,\n",
    "                       #kernel_regularizer=regularizers.l2(0.0001)))\n",
    "\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "        return model\n",
    "\n",
    "    model = compilemodel()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.31910606, 5.25887663, 5.34927753, ..., 5.42569721, 5.15267048,\n",
       "       5.16879202])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = compilemodel()\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=500,\n",
    "#     shuffle=True,\n",
    "#     verbose=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "# metrics = list(history.history.keys())\n",
    "# style = ['r-','ro','b-','bo']\n",
    "\n",
    "# plt.figure() \n",
    "# for metric,style in  zip(metrics,style): \n",
    "    \n",
    "#     plt.plot(history.history[metric],style,label=metric)\n",
    "    \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which = 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "totalepochs = 0\n",
    "timethrough = 0\n",
    "\n",
    "\n",
    "\n",
    "testRMSLElist = []\n",
    "trainRMSLElist = []\n",
    "difflist = []\n",
    "\n",
    "while which == 'NN':\n",
    "    \n",
    "    model = compilemodel()\n",
    "\n",
    "    \n",
    "    for x in range(epochs):\n",
    "\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=1,\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "        )\n",
    "        if x % 5 == 0 and x != 0:\n",
    "            testpredictions = model.predict(X_test)\n",
    "            trainpredictions = model.predict(X_train)\n",
    "\n",
    "            testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "            trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "            \n",
    "            if tolog == 'Yes':\n",
    "                testpredictions = np.power(10, testpredictions)\n",
    "                trainpredictions = np.power(10, trainpredictions)\n",
    "                y_test = np.power(10, y_test)\n",
    "                y_train = np.power(10, y_train)\n",
    "\n",
    "\n",
    "            testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "            trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "            diff = round(abs(testRMSLE - trainRMSLE), 4)\n",
    "            \n",
    "            testRMSLElist.append(testRMSLE)\n",
    "            trainRMSLElist.append(trainRMSLE)\n",
    "            difflist.append(diff)\n",
    "            \n",
    "            if tolog == 'Yes':\n",
    "                testpredictions = np.log10(testpredictions)\n",
    "                trainpredictions = np.log10(trainpredictions)\n",
    "                y_test = np.log10(y_test)\n",
    "                y_train = np.log10(y_train)\n",
    "\n",
    "            clear_output()\n",
    "            xaxis = np.arange(0, len(testRMSLElist) * 5, 5)\n",
    "            plt.plot(xaxis, trainRMSLElist, 'r--', label='train')\n",
    "            plt.plot(xaxis, testRMSLElist, label='test')\n",
    "            plt.legend()\n",
    "            \n",
    "            \n",
    "            plt.ylim(0, .25)\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "            print(f'{x + 1 + timethrough * epochs}, trainRMSLE = {round(trainRMSLE,4)}, testRMSLE={round(testRMSLE, 4)}, diff={diff}')        \n",
    "\n",
    "\n",
    "    totalepochs+=epochs\n",
    "    timethrough+=1\n",
    "    which = pyautogui.confirm(buttons=['NN', 'stop'])\n",
    "    if which == 'stop':\n",
    "        which = 'NN'\n",
    "        error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "if which == 'NN':\n",
    "\n",
    "    folds = 1\n",
    "    epochs = 500\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    kf.get_n_splits(inputs, prices)\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(inputs, prices)):\n",
    "        X_train.append(inputs[train_index])\n",
    "        X_test.append(inputs[test_index])\n",
    "        y_train.append(prices[train_index])\n",
    "        y_test.append(prices[test_index])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    historylist = []\n",
    "\n",
    "    for fold in range(folds):\n",
    "        clear_output()\n",
    "        print(fold + 1)\n",
    "        \n",
    "        model = compilemodel()\n",
    "        \n",
    "        historylist.append(model.fit(\n",
    "            X_train[fold],\n",
    "            y_train[fold],\n",
    "            validation_data=(X_test[fold], y_test[fold]),\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "        ))\n",
    "    \n",
    "    clear_output()\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    addlist = {}\n",
    "    for key in historylist[0].history.keys():\n",
    "        addlist[key] = []\n",
    "        for fold in range(folds):\n",
    "            addlist[key].append(historylist[fold].history[key])\n",
    "\n",
    "    dftrainmse = pd.DataFrame()\n",
    "    dftestmse = pd.DataFrame()\n",
    "\n",
    "    for fold in range(folds):        \n",
    "        dftestmse[fold] = addlist['val_mean_squared_error'][fold]\n",
    "        dftrainmse[fold] = addlist['mean_squared_error'][fold]\n",
    "\n",
    "    dftestmse['avg'] = dftestmse.mean(axis=1)\n",
    "    dftrainmse['avg'] = dftrainmse.mean(axis=1)\n",
    "\n",
    "    avgtestmse = dftestmse['avg'].tolist()\n",
    "    avgtrainmse = dftrainmse['avg'].tolist()\n",
    "\n",
    "\n",
    "    plt.plot(avgtrainmse, 'r--', label = 'train')\n",
    "    plt.plot(avgtestmse, label = 'test')\n",
    "    plt.ylim(0, .3)\n",
    "    # plt.xlim(150, 300)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN' or which == 'stop':\n",
    "    which = 'NN'\n",
    "    totalepochs = int(pyautogui.prompt(text='Enter epochs', default=totalepochs))\n",
    "    print(f'Epochs = {totalepochs}')\n",
    "    model = compilemodel()\n",
    "    model.fit(\n",
    "        inputs,\n",
    "        prices,\n",
    "        epochs=totalepochs,\n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "    predictions = model.predict(testinputs)\n",
    "    predictions[predictions < prices.min()/2] = prices.min()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    print(predictions[0][0], len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    predicted = model.predict(X_test)\n",
    "    # y_train = np.power(10, y_train)\n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    if tolog == 'Yes':\n",
    "        predicted_graph = np.power(10, predicted)\n",
    "        y_test_graph = np.power(10, y_test)\n",
    "    else:\n",
    "        predicted_graph = predicted\n",
    "        y_test_graph = y_test\n",
    "        \n",
    "    print(predicted_graph.shape, y_test_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_test_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    predicted = model.predict(X_train)\n",
    "    if tolog == 'Yes':\n",
    "        predicted_graph = np.power(10, predicted)\n",
    "        y_train_graph = np.power(10, y_train)\n",
    "    else:\n",
    "        predicted_graph = predicted\n",
    "        y_train_graph = y_train\n",
    "        \n",
    "    print(predicted_graph.shape, y_train_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_train_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    lastRMSLE = 1\n",
    "    lastDiff = 1\n",
    "\n",
    "    for C in range(180, 220, 20):\n",
    "        print(f'C={C}')\n",
    "\n",
    "        for degree in range(5, 7):\n",
    "\n",
    "            for epsilon in [0.1, 1, 10, 20, 50, 75, 100]:\n",
    "\n",
    "                \n",
    "                for coef0 in range(2,3):\n",
    "                    clf = SVR(kernel='poly', C=C, gamma='auto', degree=degree, epsilon=epsilon, coef0=coef0)\n",
    "                    clf.fit(X_train, y_train) \n",
    "                    testpredictions = clf.predict(X_test)\n",
    "                    trainpredictions = clf.predict(X_train)\n",
    "\n",
    "\n",
    "                    testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "                    trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "                    \n",
    "                    if tolog == 'Yes':\n",
    "                        testpredictions = np.power(10, testpredictions)\n",
    "                        trainpredictions = np.power(10, trainpredictions)\n",
    "                        y_test = np.power(10, y_test)\n",
    "                        y_train = np.power(10, y_train)\n",
    "                    \n",
    "\n",
    "                    testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "                    trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "                    if tolog == 'Yes':\n",
    "                        testpredictions = np.log10(testpredictions)\n",
    "                        trainpredictions = np.log10(trainpredictions)\n",
    "                        y_test = np.log10(y_test)\n",
    "                        y_train = np.log10(y_train)\n",
    "                    \n",
    "                    \n",
    "                    diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "                    lastDiff = .01\n",
    "                    if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "                        lastDiff = diff\n",
    "                        lastRMSLE = testRMSLE                    \n",
    "                        print(f'C={C}, degree={degree}, epsilon={epsilon}, coef0={coef0}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}, dropcolumns={dropcolumns}')\n",
    "                        Cbest = C\n",
    "                        degreebest = degree\n",
    "                        epsilonbest = epsilon\n",
    "                        coef0best = coef0\n",
    "        \n",
    "    print('---Done---')\n",
    "    #C=130,degree=7,epsilon=0.1,coef0=3 0.1359030945302552 first submission\n",
    "    #C=190,degree=9,epsilon=0.9,coef0=2 0.1359030945302552 second?\n",
    "    #C=100,degree=7,epsilon=0.1,coef0=2 0.1359030945302552\n",
    "    #C=200, degree=7, epsilon=4, coef0=2, standard scaler, no normalizing output data, 0.1248 Kaggle Score\n",
    "    #C=210, degree=5, epsilon=13, coef0=3, trainRMSLE = 0.1, testRMSLE=0.13396, diff=0.034, no feat eng, no target scaling, dropcolumns = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        y_train = np.power(10, y_train)\n",
    "        \n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    predicted_graph = predicted\n",
    "    y_test_graph = predicted\n",
    "    print(predicted_graph.shape, y_test_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_test_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    predicted = clf.predict(X_train)\n",
    "    if tolog == 'Yes':\n",
    "        y_train = np.power(10, y_train)\n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    predicted_graph = predicted\n",
    "    y_train_graph = predicted\n",
    "    print(predicted_graph.shape, y_train_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_train_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    try:\n",
    "#         clf = SVR(kernel='poly', gamma='auto', C=240, degree=5, epsilon=0.1, coef0=2)#base\n",
    "#         clf = SVR(kernel='poly', gamma='auto', C=100, degree=6, epsilon=0.1, coef0=2)\n",
    "        #C=280, degree=6, epsilon=0.1, coef0=2, with newly cleaned data\n",
    "        sfa\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=80, degree=5, epsilon=20, coef0=2)      \n",
    "        print('Used entered hyperparameters')\n",
    "        print(clf)\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=Cbest, degree=degreebest, epsilon=epsilonbest, coef0=coef0best)\n",
    "        print(f'C={Cbest}, degree={degreebest}, epsilon={epsilonbest}, coef0={coef0best}')\n",
    "    \n",
    "    clf.fit(inputs, prices) \n",
    "    predictions = clf.predict(testinputs)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "    predictions[predictions < y_train.min()/2] = y_train.min()\n",
    "    # predictions = Y_scaler.inverse_transform(predictions)\n",
    "\n",
    "\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - RBF':\n",
    "    \n",
    "    lastRMSLE = 1\n",
    "    for C in [1e0, 1e1, 1e2, 1e3]:\n",
    "\n",
    "        for gamma in np.logspace(-2, 2, 5):\n",
    "\n",
    "            for epsilon in range(1,10):\n",
    "                epsilon = epsilon/10\n",
    "\n",
    "                clf = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=epsilon)\n",
    "                clf.fit(X_train, y_train) \n",
    "                testpredictions = clf.predict(X_test)\n",
    "                trainpredictions = clf.predict(X_train)\n",
    "                \n",
    "                testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "                trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "                \n",
    "                if tolog == 'Yes':\n",
    "                    testpredictions = np.power(10, testpredictions)\n",
    "                    trainpredictions = np.power(10, trainpredictions)\n",
    "                    y_test = np.power(10, y_test)\n",
    "                    y_train = np.power(10, y_train)\n",
    "\n",
    "                testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "                trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "                if tolog == 'Yes':\n",
    "                    testpredictions = np.log10(testpredictions)\n",
    "                    trainpredictions = np.log10(trainpredictions)\n",
    "                    y_test = np.log10(y_test)\n",
    "                    y_train = np.log10(y_train)\n",
    "\n",
    "                diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "                lastDiff = .05\n",
    "                if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "                    lastDiff = diff\n",
    "                    lastRMSLE = testRMSLE                    \n",
    "                    print(f'C={C}, gamma={gamma}, epsilon={epsilon}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}')\n",
    "                    Cbest = C\n",
    "                    gammabest = gamma\n",
    "                    epsilonbest = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - RBF':\n",
    "    clf = SVR(kernel='rbf', C=Cbest, gamma=gammabest, epsilon=epsilonbest)\n",
    "    clf.fit(X_train, y_train) \n",
    "    predictions = clf.predict(testinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Lin':\n",
    "    \n",
    "    lastRMSLE = 1\n",
    "    lastDiff = 1\n",
    "\n",
    "    for C in range(1, 40, 1):\n",
    "\n",
    "        clf = SVR(kernel='linear', C=C, gamma='auto')\n",
    "        clf.fit(X_train, y_train) \n",
    "        testpredictions = clf.predict(X_test)\n",
    "        trainpredictions = clf.predict(X_train)\n",
    "        \n",
    "        testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "        trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "\n",
    "        if tolog == 'Yes':\n",
    "            testpredictions = np.power(10, testpredictions)\n",
    "            trainpredictions = np.power(10, trainpredictions)\n",
    "            y_test = np.power(10, y_test)\n",
    "            y_train = np.power(10, y_train)\n",
    "\n",
    "\n",
    "        try:\n",
    "            testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "            trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "        except Exception as e:\n",
    "            print(f'Error with {C}, {e}')\n",
    "            continue\n",
    "\n",
    "        if tolog == 'Yes':\n",
    "            testpredictions = np.log10(testpredictions)\n",
    "            trainpredictions = np.log10(trainpredictions)\n",
    "            y_test = np.log10(y_test)\n",
    "            y_train = np.log10(y_train)\n",
    "\n",
    "        diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "        lastDiff = .05\n",
    "        if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "            lastDiff = diff\n",
    "            lastRMSLE = testRMSLE                    \n",
    "            print(f'C={C}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}')\n",
    "            Cbest = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Lin':\n",
    "    try:\n",
    "        sa\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=16)      \n",
    "        print('Used entered hyperparameters')\n",
    "        print(clf)\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=Cbest)\n",
    "        print(f'C={Cbest}')\n",
    "    \n",
    "    clf.fit(inputs, prices) \n",
    "    predictions = clf.predict(testinputs)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "    predictions[predictions < y_train.min()/2] = y_train.min()\n",
    "    # predictions = Y_scaler.inverse_transform(predictions)\n",
    "\n",
    "\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9294304614982759, RMSLE: 0.10614678316383754, dropcolumns: 235\n"
     ]
    }
   ],
   "source": [
    "if which == 'Linear':\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fitting our model with all of our features in X\n",
    "    model.fit(inputs, prices)\n",
    "\n",
    "    score = model.score(inputs, prices)\n",
    "\n",
    "    predictions = model.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    predictions = model.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f'R2: {score}, RMSLE: {RMSLE}, dropcolumns: {dropcolumns}')\n",
    "    #0.12363, R2 Score = .94, RMSLE = .0977, no scaling, drop columns = 150\n",
    "    #.12054, R2: 0.9361934187245556, RMSLE: 0.10093248123296446, dropcolumns: 200\n",
    "    #.12057, R2: 0.9299809808208424, RMSLE: 0.10573194685650467, dropcolumns: 225, with all feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.10673656439286405, R2: 0.9286440820917012, dropcolumns: 235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for alpha in range(1):\n",
    "    alpha = alpha/10\n",
    "    lasso = Lasso(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = lasso.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = lasso.score(inputs, prices)\n",
    "\n",
    "    predictions = lasso.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")\n",
    "#.11974, alpha: 0.0, RMSLE: 0.1062362486329152, R2: 0.9293114626723123, dropcolumns: 225  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.10616069478710691, R2: 0.9294119659777746, dropcolumns: 235\n",
      "alpha: 0.1, RMSLE: 0.10707867981301657, R2: 0.9281859216974832, dropcolumns: 235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for alpha in range(2):\n",
    "    alpha = alpha/10\n",
    "    ridge = Ridge(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = ridge.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = ridge.score(inputs, prices)\n",
    "\n",
    "    predictions = ridge.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.1089319655373888, R2: 0.9256785274106578, dropcolumns: 243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "for alpha in range(1):\n",
    "    alpha = alpha/10\n",
    "    elasticnet = ElasticNet(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = elasticnet.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = elasticnet.score(inputs, prices)\n",
    "\n",
    "    predictions = elasticnet.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119969.32892965 161923.67163231 182702.38522791 ... 175420.26449944\n",
      " 119045.65382891 219756.45798814]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 2) 1459\n",
      "tolog = Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>122238.764481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>161656.950998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>181737.663181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>205457.308980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>180095.399097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  122238.764481\n",
       "1  1462  161656.950998\n",
       "2  1463  181737.663181\n",
       "3  1464  205457.308980\n",
       "4  1465  180095.399097"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submittest = pd.read_csv('testcleaned.csv')\n",
    "submittest = submittest[['Id']]\n",
    "submittest['SalePrice'] = predictions\n",
    "submittest.to_csv('BrandenSubmission.csv', index=False)\n",
    "print(submittest.shape, len(predictions))\n",
    "print(f'tolog = {tolog}')\n",
    "submittest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  0.,  1.,  2., 93.,  6.,  1.,  1.,  0.,  3.]),\n",
       " array([-8.39612319e+11, -6.68332862e+11, -4.97053406e+11, -3.25773950e+11,\n",
       "        -1.54494493e+11,  1.67849628e+10,  1.88064419e+11,  3.59343875e+11,\n",
       "         5.30623332e+11,  7.01902788e+11,  8.73182244e+11]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014828069802926043"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_groupings = {}\n",
    "\n",
    "for i, column in enumerate(alldata.columns):\n",
    "    column = column.split('_')\n",
    "    if len(column) < 2:\n",
    "        continue \n",
    "    elif column[0] in category_groupings: \n",
    "        category_groupings[column[0]].append((column[1],model.coef_[i]))\n",
    "    else: \n",
    "        category_groupings[column[0]] = [(column[1], model.coef_[i])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BsmtExposure': [('Gd', 0.018104255199432373), ('No', -0.003818988800048828)],\n",
      " 'BsmtFinType1': [('GLQ', 0.0063703060150146484)],\n",
      " 'BsmtQual': [('Ex', 0.013070344924926758), ('Gd', -0.0008902549743652344)],\n",
      " 'CentralAir': [('N', -64310136122.09516), ('Y', -64310136122.06989)],\n",
      " 'ExterQual': [('Ex', 0.017604589462280273),\n",
      "               ('Gd', 0.01984572410583496),\n",
      "               ('TA', 0.012427806854248047)],\n",
      " 'Exterior2nd': [('HdBoard', -0.0031337738037109375)],\n",
      " 'FireplaceQu': [('Ex', 0.006416440010070801),\n",
      "                 ('Gd', 0.008069276809692383),\n",
      "                 ('No Value', 9.393692016601562e-05),\n",
      "                 ('TA', 0.0016527175903320312)],\n",
      " 'Foundation': [('PConc', 0.012057185173034668)],\n",
      " 'GarageFinish': [('Fin', 0.043984055519104004),\n",
      "                  ('RFn', 0.04439091682434082),\n",
      "                  ('Unf', 0.03989362716674805)],\n",
      " 'GarageType': [('Attchd', 0.007798671722412109),\n",
      "                ('Detchd', 0.012584686279296875)],\n",
      " 'HeatingQC': [('Ex', 0.006577968597412109)],\n",
      " 'HouseStyle': [('2Story', -0.006189465522766113)],\n",
      " 'KitchenQual': [('Ex', 0.023591041564941406),\n",
      "                 ('Gd', 0.0021333694458007812),\n",
      "                 ('TA', -0.0006442070007324219)],\n",
      " 'LotShape': [('IR1', -0.011621475219726562), ('Reg', -0.01151728630065918)],\n",
      " 'MSZoning': [('RL', 0.0025925636291503906), ('RM', -0.016529560089111328)],\n",
      " 'MasVnrType': [('Stone', 0.004875361919403076)],\n",
      " 'Neighborhood': [('Crawfor', 0.06238150596618652)],\n",
      " 'RoofStyle': [('Gable', 0.001745566725730896), ('Hip', 0.0021314024925231934)],\n",
      " 'SaleCondition': [('Normal', 0.029448632150888443),\n",
      "                   ('Partial', -0.010177850723266602)],\n",
      " 'SaleType': [('New', 0.05163228511810303), ('WD', -0.004759073257446289)]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(category_groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
