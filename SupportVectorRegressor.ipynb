{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyautogui'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f23808776598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyautogui\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyautogui'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "import pyautogui\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Refresh Yes\n"
     ]
    }
   ],
>>>>>>> fe36a2a582f35d3e2556962d3a838c6f0be0e72f
   "source": [
    "which = pyautogui.confirm(text='Select Model:', buttons=['SVR - Poly', 'NN', 'SVR - Lin', 'Linear'])\n",
    "load = pyautogui.confirm(text='Refresh or Existing Data:', buttons=['Refresh', 'Existing'])\n",
    "tolog = pyautogui.confirm(text='Log Target Data?', buttons=['Yes', 'No'])\n",
    "print(which, load, tolog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 3)\n",
      "(2917, 345)\n",
      "(2917, 120)\n"
     ]
    }
   ],
   "source": [
    "dropcolumns = 225\n",
    "\n",
    "inputs = pd.read_csv('traincleaned.csv')\n",
    "testinputs = pd.read_csv('testcleaned.csv')\n",
    "featureimportance = pd.read_csv('feature importance.csv')\n",
    "print(featureimportance.shape)\n",
    "featureimportance = featureimportance.rename(columns={'0': 'importance', '1':'feature'})\n",
    "featureimportance = featureimportance.drop(columns=['Unnamed: 0'])\n",
    "featureimportance = featureimportance.sort_values(by='importance')\n",
    "featureimportance = featureimportance[0:dropcolumns]\n",
    "featureimportance = featureimportance['feature'].tolist()\n",
    "\n",
    "inputs = inputs.drop(columns=['SalePrice'])\n",
    "alldata = pd.concat([inputs, testinputs])\n",
    "alldata.set_index('Id', inplace=True)\n",
    "alldata = alldata.fillna(0)\n",
    "alldata = pd.get_dummies(alldata)\n",
    "alldata = alldata.drop(columns=['Unnamed: 0'])\n",
    "print(alldata.shape)\n",
    "for column in featureimportance:\n",
    "    try:\n",
    "        alldata = alldata.drop(columns=column)\n",
    "    except:\n",
    "        print(f'Couldnt drop column {column}')\n",
    "\n",
    "print(alldata.shape)\n",
    "\n",
    "inputs = alldata.loc[0:1460,]\n",
    "testinputs = alldata.loc[1461:]\n",
    "\n",
    "numericalcolumns = []\n",
    "for column in inputs.columns:\n",
    "    if set(inputs[column].tolist()) != {0, 1}:\n",
    "        numericalcolumns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.31910606, 5.25887663, 5.34927753, ..., 5.42569721, 5.15267048,\n",
       "       5.16879202])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "prices = pd.read_csv('traincleaned.csv')\n",
    "prices = prices['SalePrice']\n",
    "prices = np.array(prices)\n",
    "if tolog == 'Yes':\n",
    "    prices = np.log10(prices)\n",
    "# Y_scaler = StandardScaler().fit(prices.reshape(-1,1))\n",
    "# prices = Y_scaler.fit_transform(prices.reshape(-1,1))\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 120) (1458,)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape, prices.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 6,
>>>>>>> fe36a2a582f35d3e2556962d3a838c6f0be0e72f
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d3a87e421d10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Refresh'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     bins = np.linspace(prices.min(), prices.max(), 4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle\n",
    "\n",
    "if load == 'Refresh' and which != 'Linear':\n",
    "    \n",
    "#     bins = np.linspace(prices.min(), prices.max(), 4)\n",
    "#     print(bins)\n",
    "#     y_binned = np.digitize(prices, bins)\n",
    "\n",
    "#     print(np.count_nonzero(y_binned == 1), np.count_nonzero(y_binned == 2), np.count_nonzero(y_binned == 3))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, prices, random_state=10, shuffle=True, test_size=.15)\n",
    "    \n",
    "\n",
    "    for column in numericalcolumns:\n",
    "        try:\n",
    "            if which == 'NN':\n",
    "                X_scaler = MinMaxScaler().fit(X_train[column].values.reshape(-1,1))\n",
    "            else:\n",
    "                X_scaler = StandardScaler().fit(X_train[column].values.reshape(-1,1))\n",
    "                \n",
    "#             X_scaler = StandardScaler().fit(inputs[column].values.reshape(-1,1))\n",
    "            \n",
    "            X_train[column] = X_scaler.fit_transform(X_train[column].values.reshape(-1,1))\n",
    "            X_test[column] = X_scaler.fit_transform(X_test[column].values.reshape(-1,1))\n",
    "            testinputs[column] = X_scaler.fit_transform(testinputs[column].values.reshape(-1,1))\n",
    "            inputs[column] = X_scaler.fit_transform(inputs[column].values.reshape(-1,1))\n",
    "        except Exception as e:\n",
    "            print(column, e)\n",
    "\n",
    "#     y_scaler = MinMaxScaler().fit(y_train.reshape(-1,1))\n",
    "#     y_train = y_scaler.fit_transform(y_train.reshape(-1,1))\n",
    "#     y_test = y_scaler.fit_transform(y_test.reshape(-1,1)) \n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    testinputs = testinputs.values\n",
    "    inputs = inputs.values\n",
    "    \n",
    "    objects = [X_train, X_test, testinputs, inputs, y_train, y_test]\n",
    "\n",
    "    with open(\"objects.txt\", \"wb\") as fp:\n",
    "        pickle.dump(objects, fp)\n",
    "        \n",
    "else:\n",
    "    if which != 'Linear':\n",
    "        with open(\"objects.txt\", \"rb\") as fp:\n",
    "            objects = pickle.load(fp)\n",
    "\n",
    "        X_train, X_test, testinputs, inputs, y_train, y_test = objects   \n",
    "    \n",
    "if which == 'Linear':\n",
    "    testinputs = testinputs.values\n",
    "    inputs = inputs.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation\n",
    "    import keras.backend as K\n",
    "    import tensorflow as tf\n",
    "    from keras import optimizers\n",
    "    from keras import regularizers\n",
    "\n",
    "    def compilemodel():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=4,\n",
    "                        activation='relu',\n",
    "                       input_dim=inputs.shape[1]))#,\n",
    "                        #kernel_regularizer=regularizers.l2(0.0001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(units=2,\n",
    "                        activation='relu',\n",
    "                       input_dim=inputs.shape[1],\n",
    "                         kernel_regularizer=regularizers.l2(0.0001)))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1,\n",
    "                       activation='linear'))#,\n",
    "                       #kernel_regularizer=regularizers.l2(0.0001)))\n",
    "\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "        return model\n",
    "\n",
    "    model = compilemodel()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.31910606, 5.25887663, 5.34927753, ..., 5.42569721, 5.15267048,\n",
       "       5.16879202])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = compilemodel()\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=500,\n",
    "#     shuffle=True,\n",
    "#     verbose=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "# metrics = list(history.history.keys())\n",
    "# style = ['r-','ro','b-','bo']\n",
    "\n",
    "# plt.figure() \n",
    "# for metric,style in  zip(metrics,style): \n",
    "    \n",
    "#     plt.plot(history.history[metric],style,label=metric)\n",
    "    \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which = 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "totalepochs = 0\n",
    "timethrough = 0\n",
    "\n",
    "\n",
    "\n",
    "testRMSLElist = []\n",
    "trainRMSLElist = []\n",
    "difflist = []\n",
    "\n",
    "while which == 'NN':\n",
    "    \n",
    "    model = compilemodel()\n",
    "\n",
    "    \n",
    "    for x in range(epochs):\n",
    "\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=1,\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "        )\n",
    "        if x % 5 == 0 and x != 0:\n",
    "            testpredictions = model.predict(X_test)\n",
    "            trainpredictions = model.predict(X_train)\n",
    "\n",
    "            testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "            trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "            \n",
    "            if tolog == 'Yes':\n",
    "                testpredictions = np.power(10, testpredictions)\n",
    "                trainpredictions = np.power(10, trainpredictions)\n",
    "                y_test = np.power(10, y_test)\n",
    "                y_train = np.power(10, y_train)\n",
    "\n",
    "\n",
    "            testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "            trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "            diff = round(abs(testRMSLE - trainRMSLE), 4)\n",
    "            \n",
    "            testRMSLElist.append(testRMSLE)\n",
    "            trainRMSLElist.append(trainRMSLE)\n",
    "            difflist.append(diff)\n",
    "            \n",
    "            if tolog == 'Yes':\n",
    "                testpredictions = np.log10(testpredictions)\n",
    "                trainpredictions = np.log10(trainpredictions)\n",
    "                y_test = np.log10(y_test)\n",
    "                y_train = np.log10(y_train)\n",
    "\n",
    "            clear_output()\n",
    "            xaxis = np.arange(0, len(testRMSLElist) * 5, 5)\n",
    "            plt.plot(xaxis, trainRMSLElist, 'r--', label='train')\n",
    "            plt.plot(xaxis, testRMSLElist, label='test')\n",
    "            plt.legend()\n",
    "            \n",
    "            \n",
    "            plt.ylim(0, .25)\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "            print(f'{x + 1 + timethrough * epochs}, trainRMSLE = {round(trainRMSLE,4)}, testRMSLE={round(testRMSLE, 4)}, diff={diff}')        \n",
    "\n",
    "\n",
    "    totalepochs+=epochs\n",
    "    timethrough+=1\n",
    "    which = pyautogui.confirm(buttons=['NN', 'stop'])\n",
    "    if which == 'stop':\n",
    "        which = 'NN'\n",
    "        error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "\n",
    "    folds = 4\n",
    "    epochs = 1000\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    kf.get_n_splits(inputs, prices)\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(inputs, prices)):\n",
    "        X_train.append(inputs[train_index])\n",
    "        X_test.append(inputs[test_index])\n",
    "        y_train.append(prices[train_index])\n",
    "        y_test.append(prices[test_index])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    historylist = []\n",
    "\n",
    "    for fold in range(folds):\n",
    "        clear_output()\n",
    "        print(fold + 1)\n",
    "        \n",
    "        model = compilemodel()\n",
    "        \n",
    "        historylist.append(model.fit(\n",
    "            X_train[fold],\n",
    "            y_train[fold],\n",
    "            validation_data=(X_test[fold], y_test[fold]),\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "        ))\n",
    "    \n",
    "    clear_output()\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    addlist = {}\n",
    "    for key in historylist[0].history.keys():\n",
    "        addlist[key] = []\n",
    "        for fold in range(folds):\n",
    "            addlist[key].append(historylist[fold].history[key])\n",
    "\n",
    "    dftrainmse = pd.DataFrame()\n",
    "    dftestmse = pd.DataFrame()\n",
    "\n",
    "    for fold in range(folds):        \n",
    "        dftestmse[fold] = addlist['val_mean_squared_error'][fold]\n",
    "        dftrainmse[fold] = addlist['mean_squared_error'][fold]\n",
    "\n",
    "    dftestmse['avg'] = dftestmse.mean(axis=1)\n",
    "    dftrainmse['avg'] = dftrainmse.mean(axis=1)\n",
    "\n",
    "    avgtestmse = dftestmse['avg'].tolist()\n",
    "    avgtrainmse = dftrainmse['avg'].tolist()\n",
    "\n",
    "\n",
    "    plt.plot(avgtrainmse, 'r--', label = 'train')\n",
    "    plt.plot(avgtestmse, label = 'test')\n",
    "    plt.ylim(0, 10000000000)\n",
    "    # plt.xlim(150, 300)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN' or which == 'stop':\n",
    "    which = 'NN'\n",
    "    totalepochs = int(pyautogui.prompt(text='Enter epochs', default=totalepochs))\n",
    "    print(f'Epochs = {totalepochs}')\n",
    "    model = compilemodel()\n",
    "    model.fit(\n",
    "        inputs,\n",
    "        prices,\n",
    "        epochs=totalepochs,\n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "    predictions = model.predict(testinputs)\n",
    "    predictions[predictions < prices.min()/2] = prices.min()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    print(predictions[0][0], len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    predicted = model.predict(X_test)\n",
    "    # y_train = np.power(10, y_train)\n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    if tolog == 'Yes':\n",
    "        predicted_graph = np.power(10, predicted)\n",
    "        y_test_graph = np.power(10, y_test)\n",
    "    else:\n",
    "        predicted_graph = predicted\n",
    "        y_test_graph = y_test\n",
    "        \n",
    "    print(predicted_graph.shape, y_test_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_test_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'NN':\n",
    "    predicted = model.predict(X_train)\n",
    "    if tolog == 'Yes':\n",
    "        predicted_graph = np.power(10, predicted)\n",
    "        y_train_graph = np.power(10, y_train)\n",
    "    else:\n",
    "        predicted_graph = predicted\n",
    "        y_train_graph = y_train\n",
    "        \n",
    "    print(predicted_graph.shape, y_train_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_train_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    lastRMSLE = 1\n",
    "    lastDiff = 1\n",
    "\n",
    "    for C in range(180, 220, 20):\n",
    "        print(f'C={C}')\n",
    "\n",
    "        for degree in range(5, 7):\n",
    "\n",
    "            for epsilon in [0.1, 1, 10, 20, 50, 75, 100]:\n",
    "\n",
    "                \n",
    "                for coef0 in range(2,3):\n",
    "                    clf = SVR(kernel='poly', C=C, gamma='auto', degree=degree, epsilon=epsilon, coef0=coef0)\n",
    "                    clf.fit(X_train, y_train) \n",
    "                    testpredictions = clf.predict(X_test)\n",
    "                    trainpredictions = clf.predict(X_train)\n",
    "\n",
    "\n",
    "                    testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "                    trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "                    \n",
    "                    if tolog == 'Yes':\n",
    "                        testpredictions = np.power(10, testpredictions)\n",
    "                        trainpredictions = np.power(10, trainpredictions)\n",
    "                        y_test = np.power(10, y_test)\n",
    "                        y_train = np.power(10, y_train)\n",
    "                    \n",
    "\n",
    "                    testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "                    trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "                    if tolog == 'Yes':\n",
    "                        testpredictions = np.log10(testpredictions)\n",
    "                        trainpredictions = np.log10(trainpredictions)\n",
    "                        y_test = np.log10(y_test)\n",
    "                        y_train = np.log10(y_train)\n",
    "                    \n",
    "                    \n",
    "                    diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "                    lastDiff = .01\n",
    "                    if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "                        lastDiff = diff\n",
    "                        lastRMSLE = testRMSLE                    \n",
    "                        print(f'C={C}, degree={degree}, epsilon={epsilon}, coef0={coef0}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}, dropcolumns={dropcolumns}')\n",
    "                        Cbest = C\n",
    "                        degreebest = degree\n",
    "                        epsilonbest = epsilon\n",
    "                        coef0best = coef0\n",
    "        \n",
    "    print('---Done---')\n",
    "    #C=130,degree=7,epsilon=0.1,coef0=3 0.1359030945302552 first submission\n",
    "    #C=190,degree=9,epsilon=0.9,coef0=2 0.1359030945302552 second?\n",
    "    #C=100,degree=7,epsilon=0.1,coef0=2 0.1359030945302552\n",
    "    #C=200, degree=7, epsilon=4, coef0=2, standard scaler, no normalizing output data, 0.1248 Kaggle Score\n",
    "    #C=210, degree=5, epsilon=13, coef0=3, trainRMSLE = 0.1, testRMSLE=0.13396, diff=0.034, no feat eng, no target scaling, dropcolumns = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        y_train = np.power(10, y_train)\n",
    "        \n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    predicted_graph = predicted\n",
    "    y_test_graph = predicted\n",
    "    print(predicted_graph.shape, y_test_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_test_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    predicted = clf.predict(X_train)\n",
    "    if tolog == 'Yes':\n",
    "        y_train = np.power(10, y_train)\n",
    "    # predicted[predicted < y_train.min()/2] = y_train.min()\n",
    "    predicted_graph = predicted\n",
    "    y_train_graph = predicted\n",
    "    print(predicted_graph.shape, y_train_graph.shape)\n",
    "    residuals = predicted_graph[0] - y_train_graph\n",
    "    xaxis = np.arange(len(residuals))\n",
    "    plt.scatter(xaxis, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Poly':\n",
    "    try:\n",
    "#         clf = SVR(kernel='poly', gamma='auto', C=240, degree=5, epsilon=0.1, coef0=2)#base\n",
    "#         clf = SVR(kernel='poly', gamma='auto', C=100, degree=6, epsilon=0.1, coef0=2)\n",
    "        #C=280, degree=6, epsilon=0.1, coef0=2, with newly cleaned data\n",
    "        sfa\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=80, degree=5, epsilon=20, coef0=2)      \n",
    "        print('Used entered hyperparameters')\n",
    "        print(clf)\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=Cbest, degree=degreebest, epsilon=epsilonbest, coef0=coef0best)\n",
    "        print(f'C={Cbest}, degree={degreebest}, epsilon={epsilonbest}, coef0={coef0best}')\n",
    "    \n",
    "    clf.fit(inputs, prices) \n",
    "    predictions = clf.predict(testinputs)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "    predictions[predictions < y_train.min()/2] = y_train.min()\n",
    "    # predictions = Y_scaler.inverse_transform(predictions)\n",
    "\n",
    "\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - RBF':\n",
    "    \n",
    "    lastRMSLE = 1\n",
    "    for C in [1e0, 1e1, 1e2, 1e3]:\n",
    "\n",
    "        for gamma in np.logspace(-2, 2, 5):\n",
    "\n",
    "            for epsilon in range(1,10):\n",
    "                epsilon = epsilon/10\n",
    "\n",
    "                clf = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=epsilon)\n",
    "                clf.fit(X_train, y_train) \n",
    "                testpredictions = clf.predict(X_test)\n",
    "                trainpredictions = clf.predict(X_train)\n",
    "                \n",
    "                testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "                trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "                \n",
    "                if tolog == 'Yes':\n",
    "                    testpredictions = np.power(10, testpredictions)\n",
    "                    trainpredictions = np.power(10, trainpredictions)\n",
    "                    y_test = np.power(10, y_test)\n",
    "                    y_train = np.power(10, y_train)\n",
    "\n",
    "                testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "                trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "\n",
    "                if tolog == 'Yes':\n",
    "                    testpredictions = np.log10(testpredictions)\n",
    "                    trainpredictions = np.log10(trainpredictions)\n",
    "                    y_test = np.log10(y_test)\n",
    "                    y_train = np.log10(y_train)\n",
    "\n",
    "                diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "                lastDiff = .05\n",
    "                if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "                    lastDiff = diff\n",
    "                    lastRMSLE = testRMSLE                    \n",
    "                    print(f'C={C}, gamma={gamma}, epsilon={epsilon}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}')\n",
    "                    Cbest = C\n",
    "                    gammabest = gamma\n",
    "                    epsilonbest = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - RBF':\n",
    "    clf = SVR(kernel='rbf', C=Cbest, gamma=gammabest, epsilon=epsilonbest)\n",
    "    clf.fit(X_train, y_train) \n",
    "    predictions = clf.predict(testinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Lin':\n",
    "    \n",
    "    lastRMSLE = 1\n",
    "    lastDiff = 1\n",
    "\n",
    "    for C in range(1, 40, 1):\n",
    "\n",
    "        clf = SVR(kernel='linear', C=C, gamma='auto')\n",
    "        clf.fit(X_train, y_train) \n",
    "        testpredictions = clf.predict(X_test)\n",
    "        trainpredictions = clf.predict(X_train)\n",
    "        \n",
    "        testpredictions[testpredictions < y_train.min()/2] = y_train.min()\n",
    "        trainpredictions[trainpredictions < y_train.min()/2] = y_train.min()\n",
    "\n",
    "        if tolog == 'Yes':\n",
    "            testpredictions = np.power(10, testpredictions)\n",
    "            trainpredictions = np.power(10, trainpredictions)\n",
    "            y_test = np.power(10, y_test)\n",
    "            y_train = np.power(10, y_train)\n",
    "\n",
    "\n",
    "        try:\n",
    "            testRMSLE = math.sqrt(mean_squared_log_error(y_test, testpredictions))\n",
    "            trainRMSLE = math.sqrt(mean_squared_log_error(y_train, trainpredictions))\n",
    "        except Exception as e:\n",
    "            print(f'Error with {C}, {e}')\n",
    "            continue\n",
    "\n",
    "        if tolog == 'Yes':\n",
    "            testpredictions = np.log10(testpredictions)\n",
    "            trainpredictions = np.log10(trainpredictions)\n",
    "            y_test = np.log10(y_test)\n",
    "            y_train = np.log10(y_train)\n",
    "\n",
    "        diff = round(abs(testRMSLE - trainRMSLE), 3)\n",
    "        lastDiff = .05\n",
    "        if testRMSLE < lastRMSLE and diff < lastDiff:\n",
    "            lastDiff = diff\n",
    "            lastRMSLE = testRMSLE                    \n",
    "            print(f'C={C}, trainRMSLE = {round(trainRMSLE,2)}, testRMSLE={round(testRMSLE, 5)}, diff={diff}')\n",
    "            Cbest = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'SVR - Lin':\n",
    "    try:\n",
    "        sa\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=16)      \n",
    "        print('Used entered hyperparameters')\n",
    "        print(clf)\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        clf = SVR(kernel='poly', gamma='auto', C=Cbest)\n",
    "        print(f'C={Cbest}')\n",
    "    \n",
    "    clf.fit(inputs, prices) \n",
    "    predictions = clf.predict(testinputs)\n",
    "    \n",
    "    if tolog == 'Yes':\n",
    "        predictions = np.power(10, predictions)\n",
    "        \n",
    "    predictions[predictions < y_train.min()/2] = y_train.min()\n",
    "    # predictions = Y_scaler.inverse_transform(predictions)\n",
    "\n",
    "\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9299809808208424, RMSLE: 0.10573194685650467, dropcolumns: 225\n"
     ]
    }
   ],
   "source": [
    "if which == 'Linear':\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fitting our model with all of our features in X\n",
    "    model.fit(inputs, prices)\n",
    "\n",
    "    score = model.score(inputs, prices)\n",
    "\n",
    "    predictions = model.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    predictions = model.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f'R2: {score}, RMSLE: {RMSLE}, dropcolumns: {dropcolumns}')\n",
    "    #0.12363, R2 Score = .94, RMSLE = .0977, no scaling, drop columns = 150\n",
    "    #.12054, R2: 0.9361934187245556, RMSLE: 0.10093248123296446, dropcolumns: 200\n",
    "    #.12057, R2: 0.9299809808208424, RMSLE: 0.10573194685650467, dropcolumns: 225, with all feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.1062362486329152, R2: 0.9293114626723123, dropcolumns: 225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for alpha in range(1):\n",
    "    alpha = alpha/10\n",
    "    lasso = Lasso(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = lasso.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = lasso.score(inputs, prices)\n",
    "\n",
    "    predictions = lasso.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")\n",
    "#.11974, alpha: 0.0, RMSLE: 0.1062362486329152, R2: 0.9293114626723123, dropcolumns: 225  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.10573000849986097, R2: 0.9299835467629097, dropcolumns: 225\n",
      "alpha: 0.1, RMSLE: 0.10658676166133288, R2: 0.9288442343123683, dropcolumns: 225\n",
      "alpha: 0.2, RMSLE: 0.1066498867084167, R2: 0.9287599254029394, dropcolumns: 225\n",
      "alpha: 0.3, RMSLE: 0.10670153455785356, R2: 0.9286909081852133, dropcolumns: 225\n",
      "alpha: 0.4, RMSLE: 0.10674877263006893, R2: 0.9286277546021474, dropcolumns: 225\n",
      "alpha: 0.5, RMSLE: 0.10679325208308306, R2: 0.9285682636027528, dropcolumns: 225\n",
      "alpha: 0.6, RMSLE: 0.1068355674970288, R2: 0.9285116440516104, dropcolumns: 225\n",
      "alpha: 0.7, RMSLE: 0.1068760075085121, R2: 0.9284575129454455, dropcolumns: 225\n",
      "alpha: 0.8, RMSLE: 0.10691475372277867, R2: 0.928405629900037, dropcolumns: 225\n",
      "alpha: 0.9, RMSLE: 0.10695194371821842, R2: 0.9283558130511477, dropcolumns: 225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for alpha in range(10):\n",
    "    alpha = alpha/10\n",
    "    ridge = Ridge(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = ridge.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = ridge.score(inputs, prices)\n",
    "\n",
    "    predictions = ridge.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0, RMSLE: 0.1062362486329152, R2: 0.9293114626723123, dropcolumns: 225\n",
      "alpha: 0.1, RMSLE: 0.12850484938084622, R2: 0.8965709777741765, dropcolumns: 225\n",
      "alpha: 0.2, RMSLE: 0.13124766177425462, R2: 0.8921086686988622, dropcolumns: 225\n",
      "alpha: 0.3, RMSLE: 0.13516790577056492, R2: 0.8855671912049655, dropcolumns: 225\n",
      "alpha: 0.4, RMSLE: 0.14043686650830617, R2: 0.8764719437474084, dropcolumns: 225\n",
      "alpha: 0.5, RMSLE: 0.14581403531844642, R2: 0.8668313662483548, dropcolumns: 225\n",
      "alpha: 0.6, RMSLE: 0.14954350940332015, R2: 0.8599321894584294, dropcolumns: 225\n",
      "alpha: 0.7, RMSLE: 0.1538311542260998, R2: 0.8517851533383142, dropcolumns: 225\n",
      "alpha: 0.8, RMSLE: 0.15851605344333258, R2: 0.8426200081808012, dropcolumns: 225\n",
      "alpha: 0.9, RMSLE: 0.16349552440976672, R2: 0.8325771783077878, dropcolumns: 225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "for alpha in range(10):\n",
    "    alpha = alpha/10\n",
    "    elasticnet = ElasticNet(alpha=alpha).fit(inputs, prices)\n",
    "\n",
    "    predictions = elasticnet.predict(inputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "    pricesunlogged = np.power(10, prices)\n",
    "\n",
    "\n",
    "    RMSLE = math.sqrt(mean_squared_log_error(pricesunlogged, predictions))\n",
    "\n",
    "    r2 = elasticnet.score(inputs, prices)\n",
    "\n",
    "    predictions = elasticnet.predict(testinputs)\n",
    "    predictions = np.power(10, predictions)\n",
    "\n",
    "    print(f\"alpha: {alpha}, RMSLE: {RMSLE}, R2: {r2}, dropcolumns: {dropcolumns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119482.01242219 160272.85257829 178805.4426838  ... 167222.3653297\n",
      " 119853.10099463 223111.84069782]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 2) 1459\n",
      "tolog = Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>119482.012422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>160272.852578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>178805.442684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>200204.819409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>178709.197351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  119482.012422\n",
       "1  1462  160272.852578\n",
       "2  1463  178805.442684\n",
       "3  1464  200204.819409\n",
       "4  1465  178709.197351"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submittest = pd.read_csv('testcleaned.csv')\n",
    "submittest = submittest[['Id']]\n",
    "submittest['SalePrice'] = predictions\n",
    "submittest.to_csv('BrandenSubmission.csv', index=False)\n",
    "print(submittest.shape, len(predictions))\n",
    "print(f'tolog = {tolog}')\n",
    "submittest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
