{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 6.000e+01, 6.500e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 2.000e+01, 8.000e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.000e+00, 6.000e+01, 6.800e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.457e+03, 7.000e+01, 6.600e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.458e+03, 2.000e+01, 6.800e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.459e+03, 2.000e+01, 7.500e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = pd.read_csv('traincleaned.csv')\n",
    "try:\n",
    "    inputs = inputs.drop(columns=['SalePrice', 'Id'])\n",
    "except:\n",
    "    inputs = inputs.drop(columns=['Id'])\n",
    "inputs = inputs.fillna(0)\n",
    "inputs = pd.get_dummies(inputs)\n",
    "inputs.head()\n",
    "inputs = inputs.values\n",
    "print(len(inputs))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500, 181500, 223500, ..., 266500, 142125, 147500], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = pd.read_csv('train.csv')\n",
    "prices = prices['SalePrice']\n",
    "prices = np.array(prices)\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 305) (1460,)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape, prices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, prices, random_state=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train_scale\n",
    "X_test = X_test_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=90, cache_size=200, coef0=0.0, degree=3, epsilon=0.5, gamma=0.2,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "clf = SVR(kernel='rbf', C=90, gamma=0.2, epsilon=.5)\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([166875.36848174, 164555.11186816, 164210.45838108, 164517.45157895,\n",
       "       164477.46134591, 165316.03377072, 165442.42275702, 164607.11735326,\n",
       "       165465.93510477, 164772.51469038, 164591.34915096, 164583.32912783,\n",
       "       165537.27037423, 164662.24898288, 165945.75978364, 164336.2910559 ,\n",
       "       164323.89761728, 164271.51516604, 164677.04863999, 164498.63331353,\n",
       "       164524.48634742, 164446.4110309 , 165248.01625061, 164923.97802275,\n",
       "       164531.93655371, 164586.20013939, 164572.06602193, 164791.30013277,\n",
       "       164978.39135725, 164346.13437606, 164548.18167531, 164202.8712325 ,\n",
       "       164150.2090177 , 164554.35343324, 164364.88774668, 165238.59478782,\n",
       "       164152.0141694 , 164540.28401579, 165006.4522098 , 164494.98823132,\n",
       "       164387.27354462, 164465.15302882, 164456.77212941, 164078.68409782,\n",
       "       165287.11237355, 164508.71584702, 164157.83906377, 165989.75790086,\n",
       "       165267.09506526, 164649.19736903, 164495.46482329, 164554.61408642,\n",
       "       164495.97324023, 166667.53457704, 166367.55125626, 164268.97077791,\n",
       "       163981.9875832 , 165195.5323649 , 164242.27177404, 165000.54051931,\n",
       "       164211.39580259, 165875.12447881, 164522.45143282, 164513.00668546,\n",
       "       164431.35624973, 164350.17501154, 164229.58257972, 165056.56517932,\n",
       "       164533.52423607, 164541.68576287, 164571.50907371, 164547.8976412 ,\n",
       "       165599.76349801, 164358.90055671, 164557.74919796, 165410.43747929,\n",
       "       165052.06162099, 164553.77030884, 165145.20614761, 164881.29535631,\n",
       "       164763.19360156, 164313.29421673, 164252.14279158, 164248.22287323,\n",
       "       164624.65824845, 164475.88993851, 164512.40158664, 164669.65596361,\n",
       "       164936.33061574, 164562.49337045, 164955.2271889 , 164580.62231002,\n",
       "       164475.71864609, 164486.34419933, 164487.86271081, 164428.57901802,\n",
       "       164204.16023739, 164397.54721667, 164406.26316648, 164336.42885532,\n",
       "       164585.24936042, 164485.57746976, 164286.39933639, 163842.32572195,\n",
       "       164095.27172386, 164543.51993057, 165372.31991261, 164571.55421887,\n",
       "       164488.4881089 , 165156.2095337 , 164499.52180858, 164536.66616798,\n",
       "       164473.18023379, 166172.04829703, 165595.95066358, 165724.53387184,\n",
       "       165638.87425496, 164017.6064893 , 164542.37918831, 164675.07268272,\n",
       "       164391.85782392, 165298.66811643, 165976.55230183, 164541.13702575,\n",
       "       164566.09907943, 164836.35306641, 164862.05847126, 164577.11210353,\n",
       "       164695.73573485, 164803.28069026, 165097.87158609, 164577.13277654,\n",
       "       164430.22070609, 163866.5678538 , 164531.50087538, 165405.08314358,\n",
       "       164843.31638204, 164804.91453016, 165960.35098426, 164502.57653104,\n",
       "       164559.02793026, 164656.95898851, 164556.07876475, 165524.33370012,\n",
       "       164557.38364528, 166429.68881342, 164447.67725067, 166152.55448145,\n",
       "       165816.93811771, 164119.12034369, 164793.03367377, 164999.42968667,\n",
       "       164247.93446837, 165127.77766161, 165273.62069822, 164841.60698025,\n",
       "       164584.74796125, 164364.06355876, 164541.07367366, 164556.15055638,\n",
       "       164581.74134666, 164313.65739186, 164561.3828767 , 164512.21361621,\n",
       "       164417.67515085, 164137.21126401, 164857.32572041, 164387.69771714,\n",
       "       164348.80548074, 164532.23645844, 165341.33398655, 164526.55727992,\n",
       "       164966.82698632, 165173.58034656, 164966.07499332, 164472.22910887,\n",
       "       164575.05909179, 165692.56156472, 164143.36643875, 164357.47175325,\n",
       "       164108.36633901, 165449.43367027, 164434.46267323, 164379.98084457,\n",
       "       165161.73328406, 164482.49950934, 165084.716621  , 165454.075328  ,\n",
       "       164518.1890151 , 164372.59909711, 163818.93494447, 164399.47138449,\n",
       "       164084.80390709, 164805.32024213, 164415.8590775 , 165007.04522229,\n",
       "       165901.15225029, 164438.98314741, 164516.93726595, 164535.35408296,\n",
       "       164973.73323092, 164756.12630864, 164521.12526715, 165617.50561367,\n",
       "       164714.91808946, 164332.02092522, 165498.65717206, 165106.01868391,\n",
       "       164603.899548  , 164587.63818889, 166633.83017119, 164230.56647467,\n",
       "       164614.9261328 , 164282.28805399, 165673.43164737, 165128.26960895,\n",
       "       164249.49126338, 164487.34249431, 164551.03070601, 164487.76244656,\n",
       "       164659.68482294, 164348.46381348, 164617.67736514, 164657.45692848,\n",
       "       164433.63288301, 164178.06208879, 166011.27423348, 164798.26493301,\n",
       "       164770.24097186, 165165.77364935, 164358.52925694, 166242.03223318,\n",
       "       164225.31364705, 164301.62945547, 165065.12376271, 164488.54232743,\n",
       "       165518.75958595, 164166.12259738, 164546.11997594, 166524.06432337,\n",
       "       165220.69567878, 164505.40743263, 164467.93135984, 164486.7521822 ,\n",
       "       164470.95320764, 164504.12178409, 164389.82080552, 164468.77035605,\n",
       "       164572.05266538, 164589.15281957, 164595.53129853, 164411.53167306,\n",
       "       165526.77912524, 164334.21577136, 164554.77175759, 164374.71419398,\n",
       "       164721.75814069, 164491.36856569, 164969.18830326, 164357.51639291,\n",
       "       165804.20156689, 164474.89589641, 166990.51308758, 164614.19877824,\n",
       "       164581.01566872, 164557.95397092, 164519.62055349, 164599.50310684,\n",
       "       164145.57700072, 164232.89446143, 164574.33646497, 164849.95740198,\n",
       "       164557.10531112, 164544.60023241, 164660.57225823, 164567.8315155 ,\n",
       "       164145.32856924, 164108.67344422, 164552.33331046, 164255.28465249,\n",
       "       164439.53160296, 164007.88696676, 164243.50975924, 164437.40000832,\n",
       "       164860.80296252, 165909.25321283, 164311.80639562, 164413.14216013,\n",
       "       165822.363864  , 164332.67301717, 164518.60412666, 165128.89463601,\n",
       "       164539.33875395, 164573.29317619, 165768.39688626, 165004.71054187,\n",
       "       165355.10487169, 165855.48329355, 164512.54561815, 163794.4796997 ,\n",
       "       164385.26181382, 164561.14246937, 164455.25039059, 164526.96935462,\n",
       "       164457.11036404, 164630.37380657, 164241.17098113, 164591.51431956,\n",
       "       164412.17978828, 165150.39053257, 164548.63446201, 164553.38870605,\n",
       "       164547.66252155, 165977.73136349, 164454.82171808, 164532.92912415,\n",
       "       165086.19822545, 164837.02275742, 164819.34177175, 164695.47133298,\n",
       "       166660.07187522, 164283.63705274, 164387.74086153, 165033.91276157,\n",
       "       164394.71240112, 164721.78734015, 165953.37304261, 166669.39094558,\n",
       "       164409.17853969, 164475.09863156, 164197.20668704, 164784.69836969,\n",
       "       165266.69005378, 165923.43419708, 164897.79801871, 164512.77969091,\n",
       "       164530.52116449, 164149.04776253, 165252.51625248, 165916.63925824,\n",
       "       165389.95118684, 164482.96964742, 164471.83133649, 164911.34862102,\n",
       "       164417.64049388, 164692.54119102, 164456.72531819, 164568.28015394,\n",
       "       165410.57368859, 164468.86077829, 165221.13023091, 164718.96270009,\n",
       "       165149.42035146, 164520.83379778, 164378.84865461, 164481.11385105,\n",
       "       165175.62640358, 164628.0037701 , 164536.42624454, 165330.80340847,\n",
       "       164686.72856697, 165426.31170437, 164349.99531833, 164972.47933606,\n",
       "       164631.73695524])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4079871296811159"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "import math\n",
    "math.sqrt(mean_squared_log_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for C in range(50,200,50):\n",
    "    \n",
    "#     for gamma in range(1, 10):\n",
    "#         gamma = gamma/10\n",
    "        \n",
    "#         for epsilon in range(1,10):\n",
    "#             epsilon = epsilon/10\n",
    "            \n",
    "#             clf = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=epsilon)\n",
    "#             clf.fit(X_train, y_train) \n",
    "#             predictions = clf.predict(X_test)\n",
    "#             error = 0\n",
    "#             for x in range(100):\n",
    "#                 error += abs(predictions[x] - y_test[x])/y_test[x]\n",
    "\n",
    "#             print(C, gamma, epsilon, error/100)\n",
    "#             break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 5 0.1 4 0.18277117879667543\n",
      "50 5 0.3 4 0.1827711796377909\n",
      "50 5 0.5 4 0.18277118052029967\n",
      "50 5 0.7 4 0.18277118126004374\n",
      "50 5 0.9 4 0.18277118205101922\n",
      "50 7 0.1 3 0.1466857625386367\n",
      "50 7 0.1 4 0.13976834562921653\n",
      "50 7 0.3 3 0.14668582351945111\n",
      "50 7 0.3 4 0.13976784846309967\n",
      "50 7 0.5 3 0.14668588480994207\n",
      "50 7 0.5 4 0.13976735157241535\n",
      "50 7 0.7 3 0.14668594594299073\n",
      "50 7 0.7 4 0.1397668541436617\n",
      "50 7 0.9 3 0.14668600737384424\n",
      "50 7 0.9 4 0.13976635732256928\n",
      "50 9 0.1 2 0.15719182863565445\n",
      "50 9 0.1 3 0.13645635671653084\n",
      "50 9 0.1 4 0.1535417862316705\n",
      "50 9 0.3 2 0.15719174098935818\n",
      "50 9 0.3 3 0.13645623339731155\n",
      "50 9 0.3 4 0.15354170003412304\n",
      "50 9 0.5 2 0.15719165310952\n",
      "50 9 0.5 3 0.13645611012233935\n",
      "50 9 0.5 4 0.15354161339878428\n",
      "50 9 0.7 2 0.15719156557095468\n",
      "50 9 0.7 3 0.13645598673791384\n",
      "50 9 0.7 4 0.15354152699999538\n",
      "50 9 0.9 2 0.15719147780937667\n",
      "50 9 0.9 3 0.13645586364941392\n",
      "50 9 0.9 4 0.15354144054635382\n",
      "70 5 0.1 4 0.1730910207459342\n",
      "70 5 0.3 4 0.17309112465984025\n",
      "70 5 0.5 4 0.1730912286125597\n",
      "70 5 0.7 4 0.1730913326232946\n",
      "70 5 0.9 4 0.17309143653595258\n",
      "70 7 0.1 3 0.14095405229273922\n",
      "70 7 0.1 4 0.14243147972636538\n",
      "70 7 0.3 3 0.1409538410135054\n",
      "70 7 0.3 4 0.14243093748075664\n",
      "70 7 0.5 3 0.14095362959551572\n",
      "70 7 0.5 4 0.1424303955384332\n",
      "70 7 0.7 3 0.14095341852753815\n",
      "70 7 0.7 4 0.14242985328640212\n",
      "70 7 0.9 3 0.14095320730402222\n",
      "70 7 0.9 4 0.14242931149070326\n",
      "70 9 0.1 2 0.14951298881301012\n",
      "70 9 0.1 3 0.13624996865223937\n",
      "70 9 0.1 4 0.15764944384678933\n",
      "70 9 0.3 2 0.1495129108568127\n",
      "70 9 0.3 3 0.13624979116856498\n",
      "70 9 0.3 4 0.15764949171226003\n",
      "70 9 0.5 2 0.14951283284043485\n",
      "70 9 0.5 3 0.1362496140573187\n",
      "70 9 0.5 4 0.15764953945691043\n",
      "70 9 0.7 2 0.14951275487395294\n",
      "70 9 0.7 3 0.1362494371456928\n",
      "70 9 0.7 4 0.15764958755619185\n",
      "70 9 0.9 2 0.14951267669217372\n",
      "70 9 0.9 3 0.1362492596651768\n",
      "70 9 0.9 4 0.15764963551708075\n",
      "90 5 0.1 4 0.16674161714041555\n",
      "90 5 0.3 4 0.16674162304373102\n",
      "90 5 0.5 4 0.16674162907699594\n",
      "90 5 0.7 4 0.16674163476032747\n",
      "90 5 0.9 4 0.16674164057645977\n",
      "90 7 0.1 2 0.19127244956900336\n",
      "90 7 0.1 3 0.13782185430373314\n",
      "90 7 0.1 4 0.1434765580353627\n",
      "90 7 0.3 2 0.19127243216220663\n",
      "90 7 0.3 3 0.13782174096773417\n",
      "90 7 0.3 4 0.14347610088839077\n",
      "90 7 0.5 2 0.19127241481420007\n",
      "90 7 0.5 3 0.13782162806484055\n",
      "90 7 0.5 4 0.14347564397984436\n",
      "90 7 0.7 2 0.19127239760706724\n",
      "90 7 0.7 3 0.13782151484023542\n",
      "90 7 0.7 4 0.14347518650493862\n",
      "90 7 0.9 2 0.19127238026536186\n",
      "90 7 0.9 3 0.13782140188717773\n",
      "90 7 0.9 4 0.14347472960436453\n",
      "90 9 0.1 2 0.144135263368988\n",
      "90 9 0.1 3 0.13681694359693575\n",
      "90 9 0.1 4 0.16181392766304162\n",
      "90 9 0.3 2 0.14413524896408905\n",
      "90 9 0.3 3 0.13681685987253892\n",
      "90 9 0.3 4 0.16181428072223503\n",
      "90 9 0.5 2 0.14413523499096695\n",
      "90 9 0.5 3 0.13681677621558092\n",
      "90 9 0.5 4 0.16181463446911645\n",
      "90 9 0.7 2 0.1441352206069673\n",
      "90 9 0.7 3 0.1368166926662977\n",
      "90 9 0.7 4 0.16181498781526027\n",
      "90 9 0.9 2 0.14413520643743097\n",
      "90 9 0.9 3 0.13681660906429455\n",
      "90 9 0.9 4 0.1618153405811536\n",
      "110 5 0.1 3 0.19409418275288468\n",
      "110 5 0.1 4 0.1623541808193816\n",
      "110 5 0.3 3 0.19409400588883285\n",
      "110 5 0.3 4 0.16235415857661611\n",
      "110 5 0.5 3 0.19409382845426576\n",
      "110 5 0.5 4 0.1623541363143355\n",
      "110 5 0.7 3 0.1940936513791008\n",
      "110 5 0.7 4 0.1623541141297618\n",
      "110 5 0.9 3 0.19409347419072592\n",
      "110 5 0.9 4 0.16235409198801748\n",
      "110 7 0.1 2 0.18403465589525878\n",
      "110 7 0.1 3 0.13622636552930825\n",
      "110 7 0.1 4 0.1430861223369616\n",
      "110 7 0.3 2 0.18403470112112733\n",
      "110 7 0.3 3 0.13622616649215774\n",
      "110 7 0.3 4 0.1430857863097718\n",
      "110 7 0.5 2 0.18403474629170613\n",
      "110 7 0.5 3 0.1362259675422695\n",
      "110 7 0.5 4 0.1430854501656473\n",
      "110 7 0.7 2 0.18403479132675135\n",
      "110 7 0.7 3 0.1362257685397418\n",
      "110 7 0.7 4 0.1430851141867414\n",
      "110 7 0.9 2 0.18403483648904465\n",
      "110 7 0.9 3 0.13622556976140016\n",
      "110 7 0.9 4 0.14308477798493893\n",
      "110 9 0.1 2 0.14064042316840533\n",
      "110 9 0.1 3 0.13821374760927754\n",
      "110 9 0.1 4 0.1658523349371552\n",
      "110 9 0.3 2 0.14064031337660068\n",
      "110 9 0.3 3 0.13821361790359113\n",
      "110 9 0.3 4 0.1658528444278323\n",
      "110 9 0.5 2 0.14064020346050543\n",
      "110 9 0.5 3 0.138213488370062\n",
      "110 9 0.5 4 0.16585335419291206\n",
      "110 9 0.7 2 0.1406400935365911\n",
      "110 9 0.7 3 0.13821335881715463\n",
      "110 9 0.7 4 0.16585386309207806\n",
      "110 9 0.9 2 0.1406399836013598\n",
      "110 9 0.9 3 0.13821322952090692\n",
      "110 9 0.9 4 0.16585437316859097\n",
      "130 5 0.1 3 0.18779858004127692\n",
      "130 5 0.1 4 0.1588440571908659\n",
      "130 5 0.3 3 0.18779863927743357\n",
      "130 5 0.3 4 0.15884395181454405\n",
      "130 5 0.5 3 0.18779869850953\n",
      "130 5 0.5 4 0.1588438465671059\n",
      "130 5 0.7 3 0.18779875796841503\n",
      "130 5 0.7 4 0.1588437412974212\n",
      "130 5 0.9 3 0.18779881725661346\n",
      "130 5 0.9 4 0.15884363593687395\n",
      "130 7 0.1 2 0.17874101376170076\n",
      "130 7 0.1 3 0.1359030945302552\n",
      "130 7 0.1 4 0.142668109657565\n",
      "130 7 0.3 2 0.17874100816341534\n",
      "130 7 0.3 3 0.13590300694349913\n",
      "130 7 0.3 4 0.14266785534867193\n",
      "130 7 0.5 2 0.1787410026814006\n",
      "130 7 0.5 3 0.1359029190884651\n",
      "130 7 0.5 4 0.1426676008497654\n",
      "130 7 0.7 2 0.1787409969865242\n",
      "130 7 0.7 3 0.1359028316681699\n",
      "130 7 0.7 4 0.14266734685713864\n",
      "130 7 0.9 2 0.1787409913590806\n",
      "130 7 0.9 3 0.1359027441687832\n",
      "130 7 0.9 4 0.1426670923809089\n",
      "130 9 0.1 2 0.13805107610937617\n",
      "130 9 0.1 3 0.13939476131920156\n"
     ]
    }
   ],
   "source": [
    "for C in range(50,200,20):\n",
    "    \n",
    "    for degree in range(4, 10):\n",
    "        \n",
    "        for epsilon in range(1,10, 2):\n",
    "            epsilon = epsilon/10\n",
    "            \n",
    "            for coef0 in range(2,4):\n",
    "            \n",
    "                clf = SVR(kernel='poly', C=C, gamma='auto', degree=degree, epsilon=epsilon, coef0=coef0)\n",
    "                clf.fit(X_train, y_train) \n",
    "                predictions = clf.predict(X_test)\n",
    "\n",
    "                RMSLE = math.sqrt(mean_squared_log_error(y_test, predictions))\n",
    "                \n",
    "                if RMSLE < .2:\n",
    "                    print(C, degree, epsilon, coef0, RMSLE)\n",
    "                \n",
    "                \n",
    "#C=130,degree=7,epsilon=0.1,coef0=3 0.1359030945302552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=130, cache_size=200, coef0=3, degree=7, epsilon=0.1, gamma='auto',\n",
       "  kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVR(kernel='poly', C=130, gamma= 'auto', degree=7, epsilon=0.1, coef0=3)\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.fit_transform(inputs)\n",
    "predictions = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submittest = pd.read_csv('testcleaned.csv')\n",
    "submittest = submittest[['Id']]\n",
    "submittest['SalePrice'] = predictions\n",
    "submittest.to_csv('submission.csv', index=False)\n",
    "submittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          2\n",
       "2          3\n",
       "3          4\n",
       "4          5\n",
       "5          6\n",
       "6          7\n",
       "7          8\n",
       "8          9\n",
       "9         10\n",
       "10        11\n",
       "11        12\n",
       "12        13\n",
       "13        14\n",
       "14        15\n",
       "15        16\n",
       "16        17\n",
       "17        18\n",
       "18        19\n",
       "19        20\n",
       "20        21\n",
       "21        22\n",
       "22        23\n",
       "23        24\n",
       "24        25\n",
       "25        26\n",
       "26        27\n",
       "27        28\n",
       "28        29\n",
       "29        30\n",
       "        ... \n",
       "1430    1431\n",
       "1431    1432\n",
       "1432    1433\n",
       "1433    1434\n",
       "1434    1435\n",
       "1435    1436\n",
       "1436    1437\n",
       "1437    1438\n",
       "1438    1439\n",
       "1439    1440\n",
       "1440    1441\n",
       "1441    1442\n",
       "1442    1443\n",
       "1443    1444\n",
       "1444    1445\n",
       "1445    1446\n",
       "1446    1447\n",
       "1447    1448\n",
       "1448    1449\n",
       "1449    1450\n",
       "1450    1451\n",
       "1451    1452\n",
       "1452    1453\n",
       "1453    1454\n",
       "1454    1455\n",
       "1455    1456\n",
       "1456    1457\n",
       "1457    1458\n",
       "1458    1459\n",
       "1459    1460\n",
       "Name: Id, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
